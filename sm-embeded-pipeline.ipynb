{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Orchestrating Jobs, Model Registration, and Continuous Deployment with Amazon SageMaker\n",
    "\n",
    "Amazon SageMaker offers Machine Learning application developers and Machine Learning operations engineers the ability to orchestrate SageMaker jobs and author reproducible Machine Learning pipelines, deploy custom-build models for inference in real-time with low latency or offline inferences with Batch Transform, and track lineage of artifacts. You can institute sound operational practices in deploying and monitoring production workflows, deployment of model artifacts, and track artifact lineage through a simple interface, adhering to safety and best-practice paradigmsfor Machine Learning application development.\n",
    "\n",
    "The SageMaker Pipelines service supports a SageMaker Machine Learning Pipeline Domain Specific Language (DSL), which is a declarative Json specification. This DSL defines a Directed Acyclic Graph (DAG) of pipeline parameters and SageMaker job steps. The SageMaker Python Software Developer Kit (SDK) streamlines the generation of the pipeline DSL using constructs that are already familiar to engineers and scientists alike.\n",
    "\n",
    "The SageMaker Model Registry is where trained models are stored, versioned, and managed. Data Scientists and Machine Learning Engineers can compare model versions, approve models for deployment, and deploy models from different AWS accounts, all from a single Model Registry. SageMaker enables customers to follow the best practices with ML Ops and getting started right. Customers are able to standup a full ML Ops end-to-end system with a single API call."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## SageMaker Pipelines\n",
    "\n",
    "Amazon SageMaker Pipelines support the following activites:\n",
    "\n",
    "* Pipelines - A Directed Acyclic Graph of steps and conditions to orchestrate SageMaker jobs and resource creation.\n",
    "* Processing Job steps - A simplified, managed experience on SageMaker to run data processing workloads, such as feature engineering, data validation, model evaluation, and model interpretation.\n",
    "* Training Job steps - An iterative process that teaches a model to make predictions by presenting examples from a training dataset.\n",
    "* Conditional step execution - Provides conditional execution of branches in a pipeline.\n",
    "* Registering Models - Creates a model package resource in the Model Registry that can be used to create deployable models in Amazon SageMaker.\n",
    "* Creating Model steps - Create a model for use in transform steps or later publication as an endpoint.\n",
    "* Parameterized Pipeline executions - Allows pipeline executions to vary by supplied parameters.\n",
    "* Transform Job steps - A batch transform to preprocess datasets to remove noise or bias that interferes with training or inference from your dataset, get inferences from large datasets, and run inference when you don't need a persistent endpoint."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Layout of the SageMaker ModelBuild Project Template\n",
    "\n",
    "The template provides a starting point for bringing your SageMaker Pipeline development to production.\n",
    "\n",
    "```\n",
    "|-- codebuild-buildspec.yml\n",
    "|-- CONTRIBUTING.md\n",
    "|-- pipelines\n",
    "|   |-- abalone\n",
    "|   |   |-- evaluate.py\n",
    "|   |   |-- __init__.py\n",
    "|   |   |-- pipeline.py\n",
    "|   |   `-- preprocess.py\n",
    "|   |-- get_pipeline_definition.py\n",
    "|   |-- __init__.py\n",
    "|   |-- run_pipeline.py\n",
    "|   |-- _utils.py\n",
    "|   `-- __version__.py\n",
    "|-- README.md\n",
    "|-- sagemaker-pipelines-project.ipynb\n",
    "|-- setup.cfg\n",
    "|-- setup.py\n",
    "|-- tests\n",
    "|   `-- test_pipelines.py\n",
    "`-- tox.ini\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "A description of some of the artifacts is provided below:\n",
    "<br/><br/>\n",
    "Your codebuild execution instructions:\n",
    "```\n",
    "|-- codebuild-buildspec.yml\n",
    "```\n",
    "<br/><br/>\n",
    "Your pipeline artifacts, which includes a pipeline module defining the required `get_pipeline` method that returns an instance of a SageMaker pipeline, a preprocessing script that is used in feature engineering, and a model evaluation script to measure the Mean Squared Error of the model that's trained by the pipeline:\n",
    "\n",
    "```\n",
    "|-- pipelines\n",
    "|   |-- abalone\n",
    "|   |   |-- evaluate.py\n",
    "|   |   |-- __init__.py\n",
    "|   |   |-- pipeline.py\n",
    "|   |   `-- preprocess.py\n",
    "\n",
    "```\n",
    "<br/><br/>\n",
    "Utility modules for getting pipeline definition jsons and running pipelines:\n",
    "\n",
    "```\n",
    "|-- pipelines\n",
    "|   |-- get_pipeline_definition.py\n",
    "|   |-- __init__.py\n",
    "|   |-- run_pipeline.py\n",
    "|   |-- _utils.py\n",
    "|   `-- __version__.py\n",
    "```\n",
    "<br/><br/>\n",
    "Python package artifacts:\n",
    "```\n",
    "|-- setup.cfg\n",
    "|-- setup.py\n",
    "```\n",
    "<br/><br/>\n",
    "A stubbed testing module for testing your pipeline as you develop:\n",
    "```\n",
    "|-- tests\n",
    "|   `-- test_pipelines.py\n",
    "```\n",
    "<br/><br/>\n",
    "The `tox` testing framework configuration:\n",
    "```\n",
    "`-- tox.ini\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### A SageMaker Pipeline\n",
    "\n",
    "The pipeline that we create follows a typical Machine Learning Application pattern of pre-processing, training, evaluation, and conditional model registration and publication, if the quality of the model is sufficient.\n",
    "\n",
    "![A typical ML Application pipeline](img/pipeline-full.png)\n",
    "\n",
    "### Getting some constants\n",
    "\n",
    "We get some constants from the local execution environment.\n",
    "\n",
    "#### Test for AB3 Octank - add -- add"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### All of thepipeline is embedded here with steps"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {},
   "outputs": [],
   "source": [
    "import boto3\n",
    "import sagemaker\n",
    "\n",
    "\n",
    "region = boto3.Session().region_name\n",
    "role = sagemaker.get_execution_role()\n",
    "#sm_session = sagemaker.session.Session(default_bucket=\"sagemaker-grewaltempl\")\n",
    "#-- try the cross account one \n",
    "sm_session = sagemaker.session.Session(default_bucket=\"sagemaker-crossaccnt\")\n",
    "default_bucket = sm_session.default_bucket()\n",
    "\n",
    "# Change these to reflect your project/business name or if you want to separate ModelPackageGroup/Pipeline from the rest of your team\n",
    "model_package_group_name = f\"TweetsModelPackageGroup-Example1\"\n",
    "pipeline_name = f\"TweetsPipeline-Example1\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "\n",
    "import boto3\n",
    "import sagemaker\n",
    "import sagemaker.session\n",
    "\n",
    "from sagemaker.estimator import Estimator\n",
    "from sagemaker.inputs import TrainingInput\n",
    "from sagemaker.model_metrics import (\n",
    "    MetricsSource,\n",
    "    ModelMetrics,\n",
    ")\n",
    "from sagemaker.processing import (\n",
    "    ProcessingInput,\n",
    "    ProcessingOutput,\n",
    "    ScriptProcessor,\n",
    "    FrameworkProcessor\n",
    ")\n",
    "from sagemaker.sklearn.processing import SKLearnProcessor\n",
    "from sagemaker.workflow.conditions import ConditionLessThanOrEqualTo\n",
    "from sagemaker.workflow.condition_step import (\n",
    "    ConditionStep,\n",
    "    JsonGet,\n",
    ")\n",
    "from sagemaker.workflow.parameters import (\n",
    "    ParameterInteger,\n",
    "    ParameterString,\n",
    ")\n",
    "from sagemaker.workflow.pipeline import Pipeline\n",
    "from sagemaker.workflow.properties import PropertyFile\n",
    "from sagemaker.workflow.steps import (\n",
    "    ProcessingStep,\n",
    "    TrainingStep,\n",
    ")\n",
    "from sagemaker.workflow.step_collections import RegisterModel\n",
    "\n",
    "from sagemaker.workflow.conditions import (\n",
    "    ConditionGreaterThanOrEqualTo,\n",
    ")\n",
    "\n",
    "from sagemaker.sklearn import SKLearnModel\n",
    "from sagemaker.xgboost import XGBoostModel\n",
    "from sagemaker.model import Model\n",
    "\n",
    "from sagemaker.workflow.steps import CreateModelStep\n",
    "\n",
    "import warnings\n",
    "warnings.simplefilter('ignore')\n",
    "warnings.filterwarnings('ignore')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using:role=arn:aws:iam::034150676293:role/service-role/AmazonSageMaker-ExecutionRole-20220322T185187:\n",
      "using SageMaker session=<sagemaker.session.Session object at 0x7f19c40b8e50>:\n",
      "pipeline:get_pipeline::processor:\n",
      "pipeline::get_pipeline:cache:config:enabled:\n",
      "Pipeline_name=SageMakerTweetsPipeline:\n",
      "Pipeline:base:job:prefix=tweets-pipeline:\n"
     ]
    }
   ],
   "source": [
    "## -- Common constants\n",
    "from sagemaker.sklearn.processing import SKLearnProcessor\n",
    "from sagemaker.workflow.parameters import (\n",
    "    ParameterInteger,\n",
    "    ParameterString,\n",
    ")\n",
    "from sagemaker.workflow.properties import PropertyFile\n",
    "\n",
    "from sagemaker.processing import ProcessingInput, ProcessingOutput\n",
    "import os\n",
    "\n",
    "print(f\"Using:role={role}:\")\n",
    "print(f\"using SageMaker session={sm_session}:\")\n",
    "\n",
    "BASE_JOB_PREFIX=\"smjobs\",  # Choose any name\n",
    "BASE_DIR = os.path.dirname(os.path.realpath('__file__'))\n",
    "BASE_DIR = BASE_DIR + \"/pipelines/tweets\" # -- to simulate this jupyter file running where the pipelines will run\n",
    "\n",
    "# Parameters for pipeline execution\n",
    "processing_instance_count = ParameterInteger(\n",
    "        name=\"ProcessingInstanceCount\", default_value=1\n",
    ")\n",
    "processing_instance_type = ParameterString(\n",
    "        name=\"ProcessingInstanceType\", default_value=\"ml.m5.xlarge\"\n",
    ")\n",
    "training_instance_type = ParameterString(\n",
    "        name=\"TrainingInstanceType\", default_value=\"ml.m5.xlarge\"\n",
    ")\n",
    "model_approval_status = ParameterString(\n",
    "        name=\"ModelApprovalStatus\",\n",
    "        default_value=\"PendingManualApproval\",  # ModelApprovalStatus can be set to a default of \"Approved\" if you don't want manual approval.\n",
    ")\n",
    "input_data = ParameterString(\n",
    "        name=\"InputDataUrl\",\n",
    "        default_value=f\"s3://{default_bucket}/data/finance/combined_tweets.csvv\",  # Change this to point to the s3 location of your raw input data.\n",
    ")\n",
    "print(f\"pipeline:get_pipeline::processor:\")\n",
    "# Cache Pipeline steps to reduce execution time on subsequent executions\n",
    "\n",
    "from sagemaker.workflow.steps import CacheConfig\n",
    "cache_config = CacheConfig(enable_caching=True, expire_after=\"1d\")\n",
    "print(f\"pipeline::get_pipeline:cache:config:enabled:\")\n",
    "\n",
    "\n",
    "pipeline_name=\"SageMakerTweetsPipeline\"  # You can find your pipeline name in the Studio UI (project -> Pipelines -> name)\n",
    "base_job_prefix=\"tweets-pipeline\" # Choose any name\n",
    "\n",
    "print(f\"Pipeline_name={pipeline_name}:\")\n",
    "print(f\"Pipeline:base:job:prefix={base_job_prefix}:\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "str"
      ]
     },
     "execution_count": 73,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "type(base_job_prefix)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### PRE PROC SCRIPTS AND STEPS"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 93,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Overwriting ./pipelines/tweets/preprocess_tweets.py\n"
     ]
    }
   ],
   "source": [
    "%%writefile ./pipelines/tweets/preprocess_tweets.py\n",
    "\"\"\"Feature engineers the Tweets churn dataset.\"\"\"\n",
    "import argparse\n",
    "import logging\n",
    "import os\n",
    "import pathlib\n",
    "import requests\n",
    "import tempfile\n",
    "\n",
    "import boto3\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "import json\n",
    "\n",
    "from sklearn.compose import ColumnTransformer\n",
    "from sklearn.impute import SimpleImputer\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.preprocessing import StandardScaler, OneHotEncoder\n",
    "\n",
    "import pickle as pkl\n",
    "\n",
    "_logger = logging.getLogger()\n",
    "_logger.setLevel(logging.INFO)\n",
    "_logger.addHandler(logging.StreamHandler())\n",
    "\n",
    "\n",
    "try:\n",
    "    _logger.info(f\"Pkl:version:={pkl.format_version}\")\n",
    "    _logger.info(f\"Pandas:version:{pd.__version__}\")\n",
    "    _logger.info(f\"Numpy:version:{np.__version__}\")\n",
    "    import xgboost as xgb\n",
    "    _logger.info(f\"XGBoost:version:{xgb.__version__}\")\n",
    "except:\n",
    "    pass\n",
    "\n",
    "\n",
    "# Since we get a headerless CSV file we specify the column names here.\n",
    "\n",
    "X_columns_names =  [\n",
    "    'tweet_id', \n",
    "    'writer', \n",
    "    'post_date', \n",
    "    'body', \n",
    "    'comment_num', \n",
    "    'retweet_num',\n",
    "    'like_num', \n",
    "    'ticker_symbol'\n",
    "]\n",
    "\n",
    "Y_column = \"high_price\"\n",
    "\n",
    "\n",
    "X_columns_dtype = {\n",
    "    'tweet_id': np.float64, \n",
    "    'writer': str, \n",
    "    'post_date': np.int64, \n",
    "    'body': str, \n",
    "    'comment_num': np.int64, \n",
    "    'retweet_num': np.int64, \n",
    "    'like_num': np.int64, \n",
    "    'ticker_symbol': str\n",
    "}\n",
    "Y_column_dtype = {Y_column: np.bool} #{Y_column: np.float64}\n",
    "\n",
    "\n",
    "def merge_two_dicts(x, y):\n",
    "    \"\"\"Merges two dicts, returning a new copy.\"\"\"\n",
    "    z = x.copy()\n",
    "    z.update(y)\n",
    "    return z\n",
    "\n",
    "def listLocalDirectory(dirPath=\".\"):\n",
    "    for path, dnames, fnames in os.walk(dirPath):\n",
    "        _logger.info(f\"List::path={path}::dirNames={dnames}::fileNames={fnames}::\")\n",
    "\n",
    "def textToVectors(text, vectorizer):\n",
    "    vector = vectorizer.transform([text])\n",
    "    return sum(vector.toarray()[0])\n",
    "\n",
    "def vectorizerText(textArray):\n",
    "    from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "    # create the transform\n",
    "    vectorizer = TfidfVectorizer()\n",
    "    # tokenize and build vocab\n",
    "    vectorizer.fit(textArray)\n",
    "    return vectorizer\n",
    "\n",
    "def saveVectorizerToS3(vectorz=None, localFullPath=\"/opt/ml/processing/evalproperty/vectorizerBody.pkl\") :\n",
    "    pkl.dump(vectorz, open(localFullPath, \"wb\"))\n",
    "    _logger.info(f\"Vectorizer:saved!!:to:local:path={localFullPath}::name={vectorz}::This will be moved to the eval:location:\")\n",
    "    \n",
    "    \n",
    "    \n",
    "if __name__ == \"__main__\":\n",
    "    _logger.info(\"Starting preprocessing.\")\n",
    "    parser = argparse.ArgumentParser()\n",
    "    parser.add_argument(\"--input-data\", type=str, required=True)\n",
    "    parser.add_argument(\"--data-size\", type=int, default=100)\n",
    "    args = parser.parse_args()\n",
    "    input_data = args.input_data\n",
    "    data_size = args.data_size\n",
    "    _logger.info(f\"Data size={data_size}::\")\n",
    "    \n",
    "    \n",
    "    BASE_DIR = \"/opt/ml/processing\"\n",
    "    pathlib.Path(f\"{BASE_DIR}/data\").mkdir(parents=True, exist_ok=True)\n",
    "    _logger.info(f\"Download:data:from:s3:to:local:location:={BASE_DIR}/data::\")\n",
    "    \n",
    "    eval_dir = \"/opt/ml/processing/evalproperty\"\n",
    "    pathlib.Path(eval_dir).mkdir(parents=True, exist_ok=True)\n",
    "    _logger.info(f\"eval_dir={eval_dir}:sucessfully created for saving the vectorizers\")\n",
    "    \n",
    "    print(input_data)\n",
    "    _logger.info(f\"Input:data:={input_data}::\")\n",
    "    \n",
    "    bucket = input_data.split(\"/\")[2]\n",
    "    key = \"/\".join(input_data.split(\"/\")[3:])\n",
    "\n",
    "    _logger.info(f\"TEST:TEST:Downloading data from bucket: {bucket}, key: {key}:Willdownload to localfile:name as raw-data.csv\")\n",
    "    fn = f\"{BASE_DIR}/data/raw-data.csv\"\n",
    "    try:\n",
    "        s3 = boto3.resource(\"s3\")\n",
    "        s3.Bucket(bucket).download_file(key, fn)\n",
    "    except:\n",
    "        _logger.error(\"TEST:TEST:error:in:downloading:from:s3:ignore\")\n",
    "\n",
    "    \n",
    "\n",
    "    #fn = os.path.join(\"/opt/ml/processing/input\", \"combined_tweets.csv\")\n",
    "    \n",
    "    onlyFiles = [f for f in os.listdir(\"/opt/ml/processing/input\") if os.path.isfile(os.path.join(\"/opt/ml/processing/input\", f))]\n",
    "    _logger.info(f\"Data Downloaded::Now Reading downloaded data.:dir:/opt/ml/processing/input::And:FILES:ARE::{onlyFiles}\")\n",
    "    \n",
    "    fn = os.path.join(\"/opt/ml/processing/input\", onlyFiles[0])\n",
    "    _logger.info(f\"Data Downloaded::Now Reading downloaded data.:dir:/opt/ml/processing/input:::from:location={fn}::\")\n",
    "    \n",
    "    # read in csv\n",
    "    combinedTweetsDF = pd.read_csv(fn)\n",
    "    combinedTweetsDF = combinedTweetsDF.dropna()\n",
    "    combinedTweetsDF = combinedTweetsDF.drop_duplicates() # -- this drops duplicates\n",
    "\n",
    "    # -- FOR NOW CREATE just a 10 ROW DATA SET for FASTER processing\n",
    "    combinedTweetsDF =  combinedTweetsDF.iloc[:data_size,:]\n",
    "    # -- END 10 row data set creation\n",
    "    _logger.info(f\"After:ILOC:shape={combinedTweetsDF.shape}:\")\n",
    "    \n",
    "    # Create one binary classification target column\n",
    "    combinedTweetsDF['body_length'] = combinedTweetsDF['body'].apply( lambda x: len(x))\n",
    "    combinedTweetsDF['Y_label'] = combinedTweetsDF['body_length'].apply( lambda x: 1 if x > 115 else 0)\n",
    "    #combinedTweetsDF['Y_label'] = combinedTweetsDF.Y_label.apply(lambda x: 1 if x else 0) # -- convert to 1 and 0\n",
    "    _logger.info(f\"After:transformation:shape={combinedTweetsDF.shape}:columns={combinedTweetsDF.columns}::describe={combinedTweetsDF.describe()}::\")\n",
    "     \n",
    "    # Convert categorical variables into dummy/indicator variables.\n",
    "    #categorical_cols=['writer', 'ticker_symbol']\n",
    "    #categorical_cols_dict ={'writer':'wr', 'ticker_symbol' :'ticker' }\n",
    "    #df_multi = pd.get_dummies(combinedTweetsDF, columns=categorical_cols, prefix=categorical_cols_dict, drop_first=True)\n",
    "    df_multi = combinedTweetsDF.reindex(columns=(['Y_label'] + list([a for a in combinedTweetsDF.columns if a != 'Y_label']) ))\n",
    "    _logger.info(f\"df_multi:BEFORE:DROP:BODY:first 10 cols = {df_multi.columns[:10]}::\")\n",
    "    \n",
    "    # -- vectorize the text \n",
    "    #df_multi = df_multi[1:] # remove the header row \n",
    "    vectorizer = vectorizerText(df_multi.body)\n",
    "    saveVectorizerToS3(vectorizer, f\"{eval_dir}/vectorizerBody.pkl\")\n",
    "    df_multi['vec_text'] = df_multi.body.apply(lambda x: textToVectors(x,vectorizer ))\n",
    "    df_multi = df_multi.drop(['body'], axis=1)\n",
    "    _logger.info(f\"After:Vectorization:columns={len(df_multi.columns)}::describe={df_multi.describe()}::\")\n",
    "    _logger.info(f\"After:Vectorization:shape of data set={df_multi.shape}::len={len(df_multi)}::\")\n",
    "    \n",
    "    # -- vectorize the Writer and ticker symbol\n",
    "\n",
    "    vectorizer = vectorizerText(df_multi.writer.dropna())\n",
    "    df_multi['writer_text'] = df_multi.writer.apply(lambda x: textToVectors(x,vectorizer ))\n",
    "    df_multi = df_multi.drop(['writer'], axis=1)\n",
    "\n",
    "    vectorizer = vectorizerText(df_multi.ticker_symbol.dropna())\n",
    "    df_multi['ticker_symbol_text'] = df_multi.ticker_symbol.apply(lambda x: textToVectors(x,vectorizer ))\n",
    "    df_multi = df_multi.drop(['ticker_symbol'], axis=1)\n",
    "\n",
    "    _logger.info(f\"After:FULL:Vectorization:columns={len(df_multi.columns)}::describe={df_multi.describe()}::\")\n",
    "    _logger.info(f\"After:FULL:Vectorization:shape of data set={df_multi.shape}::len={len(df_multi)}::\")\n",
    "\n",
    "\n",
    "    \n",
    "    # Split the data\n",
    "    train_data, val_data, test_data = np.split(\n",
    "        df_multi.sample(frac=1, random_state=1729),\n",
    "        [int(0.7 * len(df_multi)), int(0.9 * len(df_multi))],\n",
    "    )\n",
    "    _logger.info(f\"Going to write it to {BASE_DIR}/train and {BASE_DIR}/test and {BASE_DIR}/val\")\n",
    "    _logger.info(f\"train_data:len={len(train_data)}::  val_data:len={len(val_data)}::  test_data:len={len(test_data)}::\")\n",
    "    pd.DataFrame(train_data).to_csv(\n",
    "        f\"{BASE_DIR}/train/train.csv\", header=False, index=False\n",
    "    )\n",
    "    pd.DataFrame(val_data).to_csv(\n",
    "        f\"{BASE_DIR}/val/val.csv\", header=False, index=False\n",
    "    )\n",
    "    pd.DataFrame(test_data).to_csv(\n",
    "        f\"{BASE_DIR}/test/test.csv\", header=False, index=False\n",
    "    )\n",
    "    \n",
    "    report_dict = {\n",
    "        \"regression_metrics\": {\n",
    "            \"mse\": {\n",
    "                \"value\": 11.1,\n",
    "                \"standard_deviation\": 89.2\n",
    "            },\n",
    "        },\n",
    "    }\n",
    "\n",
    "    output_dir = \"/opt/ml/processing/evalproperty\"\n",
    "    pathlib.Path(output_dir).mkdir(parents=True, exist_ok=True)\n",
    "\n",
    "    _logger.info(\"Evaluation:Writing out evaluation report with mse: %f\", 11.1)\n",
    "    evaluation_path = f\"{output_dir}/evaluation.json\"\n",
    "    with open(evaluation_path, \"w\") as f:\n",
    "        f.write(json.dumps(report_dict))\n",
    "\n",
    "    _logger.info(\"Evaluation: All Done !!\")    \n",
    "    \n",
    "    \n",
    "    _logger.info(\"All Done !! written out !!\")\n",
    "    \n",
    "    # ----------------   OLD TEMPLATE CODE --------------------#\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 94,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "SageMaker:pipeline:get_pipeline::Preproc:step:added=ProcessingStep(name='PreProcTweetsModelPipe', display_name=None, description=None, step_type=<StepTypeEnum.PROCESSING: 'Processing'>, depends_on=None)\n"
     ]
    }
   ],
   "source": [
    "# Processing step for feature engineering\n",
    "sklearn_processor = SKLearnProcessor(\n",
    "        framework_version=\"0.23-1\",\n",
    "        instance_type=processing_instance_type,\n",
    "        instance_count=processing_instance_count,\n",
    "        base_job_name=f\"smjobs-sklearn-tweets-preprocess/{base_job_prefix}\" ,#f\"{BASE_JOB_PREFIX}-sklearn-TweetsChurn-preprocess\",  # choose any name\n",
    "        sagemaker_session=sm_session,\n",
    "        role=role,\n",
    "    )\n",
    "\n",
    "inputs_p=[\n",
    "    ProcessingInput(\n",
    "        source=f\"s3://{default_bucket}/data/finance/combined_tweets.csv\",\n",
    "        destination='/opt/ml/processing/input'\n",
    "    ),\n",
    " ]\n",
    "outputs_p=[\n",
    "    ProcessingOutput(\n",
    "        s3_upload_mode=\"EndOfJob\",\n",
    "        output_name='train',\n",
    "        source='/opt/ml/processing/train',\n",
    "        destination=f's3://{default_bucket}/data/finance/curated/small/train'\n",
    "    ),\n",
    "    ProcessingOutput(\n",
    "        s3_upload_mode=\"EndOfJob\",\n",
    "        output_name='test',\n",
    "        source='/opt/ml/processing/test',\n",
    "        destination=f's3://{default_bucket}/data/finance/curated/small/test'\n",
    "    ),\n",
    "    ProcessingOutput(\n",
    "        s3_upload_mode=\"EndOfJob\",\n",
    "        output_name='validation',\n",
    "        source='/opt/ml/processing/val',\n",
    "        destination=f's3://{default_bucket}/data/finance/curated/small/validation'\n",
    "    ),\n",
    "    ProcessingOutput(\n",
    "        output_name=\"evaluation-property-pass\",\n",
    "        source=\"/opt/ml/processing/evalproperty\",\n",
    "        destination=f's3://{default_bucket}/data/finance/curated/small/evalproperty'\n",
    "    ),\n",
    "    \n",
    "    \n",
    "]\n",
    "# -- if we d onot create a output then this directory is never creatd on tbe processing job\n",
    "evaluation_report_preproc = PropertyFile(\n",
    "    name=\"EvaluationReportPreproc\",\n",
    "    output_name=\"evaluation-property-pass\", # -- matches the processing output name\n",
    "    path=\"evaluation.json\",\n",
    ")\n",
    "\n",
    "job_arguments_p=[\"--input-data\", f\"s3://{default_bucket}/data/finance/combined_tweets.csv\", \n",
    "              \"--data-size\", \"10000\"]\n",
    "step_process = ProcessingStep(\n",
    "        name=\"PreProcTweetsModelPipe\",  # choose any name\n",
    "        processor=sklearn_processor,\n",
    "        inputs=inputs_p,\n",
    "        outputs=outputs_p,\n",
    "        property_files=[evaluation_report_preproc],\n",
    "        code=os.path.join(BASE_DIR, \"preprocess_tweets.py\"),\n",
    "        job_arguments=job_arguments_p,\n",
    "        cache_config=cache_config\n",
    "    )    \n",
    "    \n",
    "print(f\"SageMaker:pipeline:get_pipeline::Preproc:step:added={step_process}\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Now the Training step"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 95,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Overwriting ./pipelines/tweets/modeltrain.py\n"
     ]
    }
   ],
   "source": [
    "%%writefile ./pipelines/tweets/modeltrain.py\n",
    "\n",
    "import os\n",
    "\n",
    "import pandas as pd\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "#from sklearn.externals import joblib\n",
    "import logging\n",
    "import joblib\n",
    "import pickle\n",
    "import xgboost as xgb\n",
    "import argparse\n",
    "import json\n",
    "\n",
    "_logger = logging.getLogger()\n",
    "_logger.setLevel(logging.INFO)\n",
    "_logger.addHandler(logging.StreamHandler())\n",
    "\n",
    "def merge_two_dicts(x, y):\n",
    "    \"\"\"Merges two dicts, returning a new copy.\"\"\"\n",
    "    z = x.copy()\n",
    "    z.update(y)\n",
    "    return z\n",
    "\n",
    "def listLocalDirectory(dirPath=\".\"):\n",
    "    for path, dnames, fnames in os.walk(dirPath):\n",
    "        _logger.info(f\"List::path={path}::dirNames={dnames}::fileNames={fnames}::\")\n",
    "\n",
    "def textToVectors(text, vectorizer):\n",
    "    vector = vectorizer.transform([text])\n",
    "    return sum(vector.toarray()[0])\n",
    "\n",
    "def vectorizerText(textArray):\n",
    "    from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "    # create the transform\n",
    "    vectorizer = TfidfVectorizer()\n",
    "    # tokenize and build vocab\n",
    "    vectorizer.fit(textArray)\n",
    "    return vectorizer\n",
    "\n",
    "def model_fn(model_dir):\n",
    "    model = xgb.Booster()\n",
    "    try:\n",
    "        model.load_model(os.path.join(model_dir,'xgboost-model.json'))\n",
    "    except:\n",
    "        #ignore model must be of type xgboost-model\n",
    "        print(\"error in loading the JSON version of xgboost model\")\n",
    "        model.load_model(os.path.join(model_dir,'xgboost-model'))\n",
    "        \n",
    "    return model\n",
    "\n",
    "#####  Estimator does not use the entry point script you have to use the sklearn container\n",
    "#####  so for estimator xgboost 1.01 that is in pickle format and so has to be loaded as pickle\n",
    "#####  -- since  weh have 1.5 version of xgboost -- we have to save it as json and then reload it and then do the predictions ---\n",
    "#####  that will solve the problem \n",
    "\n",
    "####  SO THIS CLASS IS NOT REALLY USED UNLESS we use sklearn estimator \n",
    "\n",
    "def _parse_args():\n",
    "    parser = argparse.ArgumentParser()\n",
    "\n",
    "    # Data, model, and output directories\n",
    "    # model_dir is always passed in from SageMaker. By default this is a S3 path under the default bucket.\n",
    "    parser.add_argument('--model_dir', type=str)\n",
    "    parser.add_argument('--sm-model-dir', type=str, default=os.environ.get('SM_MODEL_DIR'))\n",
    "    parser.add_argument('--train', type=str, default=os.environ.get('SM_CHANNEL_TRAINING'))\n",
    "    parser.add_argument('--hosts', type=list, default=json.loads(os.environ.get('SM_HOSTS')))\n",
    "    parser.add_argument('--current-host', type=str, default=os.environ.get('SM_CURRENT_HOST'))\n",
    "\n",
    "    return parser.parse_known_args()\n",
    "\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    _logger.info(f\"Model:xgboost:version:{xgb.__version__}\")\n",
    "    args, unknown_args = _parse_args()\n",
    "    _logger.info(f\"Model:xgboost:unknown_args={unknown_args}::args={args}::\")\n",
    "    \n",
    "    training_data_directory = \"/opt/ml/input/data/train\"\n",
    "    train_data = os.path.join(training_data_directory, \"train.csv\")\n",
    "    _logger.info(f\"Model:Logistic:regression:Reading input data from {training_data_directory}:\")\n",
    "\n",
    "    train_df = pd.read_csv(train_data, header=None)\n",
    "    X_train = train_df.iloc[:,1:]\n",
    "    y_train = train_df.iloc[:,:1]\n",
    "    _logger.info(f\"Model:train_df={train_df.shape}::X_train:shape={X_train.shape}:: y_train={y_train.shape}::\")\n",
    "     \n",
    "    #model = LogisticRegression(class_weight=\"balanced\", solver=\"lbfgs\")\n",
    "    param_dict = { 'objective':'binary:logistic'}\n",
    "    model = xgb.XGBClassifier(**param_dict)\n",
    "    _logger.info(\"Model:Training XGBOOST model\")\n",
    "    model.fit(X_train, y_train)\n",
    "    \n",
    "    #model_output_directory = os.path.join(\"/opt/ml/model\", \"model.joblib\")\n",
    "    #model_output_directory = os.path.join(\"/opt/ml/model\", \"xgboost-model.pkl\")\n",
    "    #_logger.info(\"OLDER:PKL:Model:Saving model to {}\".format(model_output_directory))\n",
    "    \n",
    "    #pickle.dump(model, open(model_output_directory, 'wb'))\n",
    "    #joblib.dump(model, model_output_directory)\n",
    "    \n",
    "    model_output_directory = os.path.join(\"/opt/ml/model\", \"xgboost-model.json\")\n",
    "    _logger.info(\"Model:Saving model to {}\".format(model_output_directory))\n",
    "    model.save_model(model_output_directory)\n",
    "\n",
    "    _logger.info(\"Model:Trained:ALL Done added !!!\")\n",
    "\n",
    "       \n",
    "    \n",
    "    # ----------------   OLD TEMPLATE CODE --------------------#\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 96,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "SageMaker:pipeline:get_pipeline::TRAINING:step:added=TrainingStep(name='TrainTweetsStep', display_name=None, description=None, step_type=<StepTypeEnum.TRAINING: 'Training'>, depends_on=None)\n"
     ]
    }
   ],
   "source": [
    "import boto3\n",
    "from sagemaker.xgboost.estimator import XGBoost\n",
    "from sagemaker import TrainingInput\n",
    "\n",
    "# -- CANNOT USE this for Sagemaker Algorithims \n",
    "metrics_definetion = [\n",
    "        {'Name': 'train:loss', 'Regex': 'loss: ([0-9\\\\.]+)'},\n",
    "        {'Name': 'train.accuracy', 'Regex': 'accuracy: ([0-9\\\\.]+)'},\n",
    "        {'Name': 'validation.loss', 'Regex': 'val_loss: ([0-9\\\\.]+)'},\n",
    "        {'Name': 'validation.accuracy', 'Regex': 'val_accuracy: ([0-9\\\\.]+)'},\n",
    "]\n",
    "xgb_hyperparams = dict (\n",
    "        objective=\"reg:linear\",\n",
    "        num_round=50,\n",
    "        max_depth=5,\n",
    "        eta=0.2,\n",
    "        gamma=4,\n",
    "        min_child_weight=6,\n",
    "        subsample=0.7,\n",
    "        silent=0,\n",
    "    )\n",
    "\n",
    "use_spot_instances = True\n",
    "max_run = 3600\n",
    "max_wait = 7200 if use_spot_instances else None\n",
    "\n",
    "xgb_custom_estimator = XGBoost(\n",
    "    role=role, \n",
    "    entry_point=os.path.join(BASE_DIR, 'modeltrain.py'),\n",
    "    framework_version=\"1.3-1\",\n",
    "    instance_count=1,\n",
    "    instance_type='ml.m5.large', # - 'local', only if docker is installed locally \n",
    "    output_path=f's3://{default_bucket}/pipeline/model/xgbtrain/modeltweet',\n",
    "    use_spot_instances=use_spot_instances,\n",
    "    max_run=max_run,\n",
    "    max_wait=max_wait,\n",
    "    hyperparameters=xgb_hyperparams,\n",
    "    base_job_name=f\"TrainTweetsModelPipe/{base_job_prefix}\",\n",
    "    code_location=f\"s3://{default_bucket}/pipeline/model/xgbtrain/code\", \n",
    "    #source_dir=\"scripts\", # This line will tell SageMaker to first install defined dependencies from scrits/requirements.txt,\n",
    "    # -- and then to upload all code inside of this folder to your container.\n",
    "    #metric_definitions=metrics_definetion, # -- using XgBoost cannot override default SageMaker metrics\n",
    "\n",
    ")\n",
    "\n",
    "step_train = TrainingStep(\n",
    "    name=\"TrainTweetsStep\",\n",
    "    estimator=xgb_custom_estimator,\n",
    "    inputs={\n",
    "        \"train\": TrainingInput( # -- name need to match output name of pre proc\n",
    "                s3_data=step_process.properties.ProcessingOutputConfig.Outputs[\n",
    "                    \"train\" \n",
    "                ].S3Output.S3Uri,\n",
    "                content_type=\"text/csv\",\n",
    "        ),\n",
    "        \"validation\": TrainingInput(\n",
    "                s3_data=step_process.properties.ProcessingOutputConfig.Outputs[\n",
    "                    \"validation\"\n",
    "                ].S3Output.S3Uri,\n",
    "                content_type=\"text/csv\",\n",
    "        ),\n",
    "    },\n",
    "    cache_config=cache_config\n",
    ")\n",
    "\n",
    "print(f\"SageMaker:pipeline:get_pipeline::TRAINING:step:added={step_train}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Now evaluation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 97,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Overwriting ./pipelines/tweets/scripts_eval/evaluate.py\n"
     ]
    }
   ],
   "source": [
    "%%writefile ./pipelines/tweets/scripts_eval/evaluate.py\n",
    "\n",
    "import json\n",
    "import logging\n",
    "import pathlib\n",
    "import pickle\n",
    "import tarfile\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import xgboost as xgb\n",
    "\n",
    "from sklearn.metrics import mean_squared_error\n",
    "from sklearn.metrics import classification_report, roc_auc_score, accuracy_score\n",
    "\n",
    "logger = logging.getLogger()\n",
    "logger.setLevel(logging.INFO)\n",
    "logger.addHandler(logging.StreamHandler())\n",
    "\n",
    "#####  Estimator does not use the entry point script you have to use the sklearn container\n",
    "#####  so for estimator xgboost 1.0.1 model is saved in that is in pickle format and so has to be loaded as pickle\n",
    "#####  -- since  weh have 1.5 version of xgboost locally -- we have to save it as json and then reload it and then do the predictions ---\n",
    "#####  that will solve the problem \n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    logger.info(\"Evaluation:Starting evaluation. Wioth DMATRIX as Test \")\n",
    "    logger.info(f\"Evaluation:xgboost:version={xgb.__version__}:\")\n",
    "    model_path = \"/opt/ml/processing/model/model.tar.gz\"\n",
    "    with tarfile.open(model_path) as tar:\n",
    "        tar.extractall(path=\".\")\n",
    "\n",
    "    model = None\n",
    "\n",
    "    if model == None:\n",
    "        try:\n",
    "            logger.info(\"Evaluation:Loading xgboost model as JSON:: and :: BOOSTER :  \")\n",
    "            model = xgb.Booster()\n",
    "            model.load_model(\"xgboost-model.json\")\n",
    "        except:\n",
    "            import traceback\n",
    "            err_str = traceback.format_exc()\n",
    "            logger.error(f\"Evaluation::error in loading BOOSTER:JSON:Booster:err_str={err_str}::\")\n",
    "    \n",
    "    if model == None:\n",
    "        try:\n",
    "            logger.info(\"Evaluation:Loading xgboost model as BOOSTER : DIRECTLY: \")\n",
    "            model = xgb.Booster()\n",
    "            model.load_model(\"xgboost-model\")\n",
    "        except:\n",
    "            import traceback\n",
    "            err_str = traceback.format_exc()\n",
    "            logger.error(f\"Evaluation::error in loading BOOSTER:Booster:err_str={err_str}::\")\n",
    "            \n",
    "            \n",
    "    if model == None:        \n",
    "        try:\n",
    "            logger.info(\"Evaluation:Loading xgboost model as pkl which is interesting \")\n",
    "            model = pickle.load(open(\"xgboost-model\", \"rb\"))\n",
    "        except:\n",
    "            import traceback\n",
    "            err_str = traceback.format_exc()\n",
    "            logger.error(f\"Evaluation::error in loading pickle file:pkl::err_str={err_str}:: This is fatal error!\")\n",
    "\n",
    "            \n",
    "    logger.info(f\"Evaluation:Model Loaded successfully:model={model}\")\n",
    "    \n",
    "    logger.info(\"Evaluation:Reading test data.\")\n",
    "    test_path = \"/opt/ml/processing/test/test.csv\"\n",
    "    df_t = pd.read_csv(test_path, header=None)\n",
    "\n",
    "    logger.info(f\"Evaluation:Reading test data.df_t:shape={df_t.shape}:\")\n",
    "    y_test = df_t.iloc[:, 0].to_numpy()\n",
    "    X_test = df_t.iloc[:,1:].to_numpy() \n",
    "\n",
    "    logger.info(\"Evaluation:Performing predictions against test data. using DMATRIX  \")\n",
    "    logger.info(\"We have to do a bit of hack to load XGBClassfier in correct format and VERSION\")\n",
    "    predictions = np.array([]) # cannot be None\n",
    "\n",
    "    try:# -- original code with DMatrix\n",
    "        logger.info(f\"Evaluate:xgboost:DMatrix:version::{xgb.__version__}\")\n",
    "        X_test_dmat = xgb.DMatrix(X_test)\n",
    "        print(f\"Evaluate:trying:original:model:predictions:shape:is:rows:={X_test_dmat.num_row()}::cols={X_test_dmat.num_col()}\")\n",
    "        predictions = model.predict(X_test_dmat)\n",
    "        logger.info(\"Evaluate:Original:model:predictions:successfully:obtained::\")\n",
    "        logger.info(f\"Evaluate:Original:model:predictions:size={predictions.size}\")\n",
    "    except:\n",
    "        import traceback\n",
    "        err_str = traceback.format_exc()\n",
    "        logger.error(f\"Evaluate:error:Original:PREDICTIONS:DMAT:FAILED:traceback={err_str}::\")\n",
    "    \n",
    "    if predictions.size <= 0:\n",
    "        try:# -- original code with DMatrix\n",
    "            logger.info(f\"Evaluate:xgboost:DF_T:Dmatrix:version::{xgb.__version__}\")\n",
    "            df_t_copy = df_t.drop(df_t.columns[0], axis=1)\n",
    "            X_test_orig = xgb.DMatrix(df_t_copy.values)\n",
    "            print(f\"Evaluate:trying:original:model:predictions:shape=rows={X_test_orig.num_row()}::cols={X_test_orig.num_col()}\")\n",
    "            predictions = model.predict(X_test_orig)\n",
    "            logger.info(\"Evaluate:Original:model:predictions:successfully:obtained::\")\n",
    "            logger.info(f\"Evaluate:Original:model:predictions:size={predictions.size}\")\n",
    "        except:\n",
    "            import traceback\n",
    "            err_str = traceback.format_exc()\n",
    "            logger.error(f\"Evaluate:error:Original:PREDICTIONS:IGNORE:traceback={err_str}::\")\n",
    "        \n",
    "    # -- end original code  \n",
    "    # -- now try the new code \n",
    "    if predictions.size <= 0:\n",
    "        try:\n",
    "\n",
    "            logger.info(\"Evaluate:predictions:Trying:Predict:directly!!\")\n",
    "            predictions = model.predict(X_test)\n",
    "        except:\n",
    "            import traceback\n",
    "            err_str = traceback.format_exc()\n",
    "            logger.error(f\"Evaluate:error:DIRECTLY:traceback={err_str}::\")\n",
    "            \n",
    "    if predictions.size <= 0:\n",
    "        try:\n",
    "            logger.error(f\"Evaluate:GOING:TO:CREATE:NEW:MODEL:AND:Trying predictions with NEW Model now\")\n",
    "            import xgboost as xgb\n",
    "            model.save_model(\"temp-model.json\")\n",
    "            model2 = xgb.XGBClassifier()\n",
    "            model2.load_model(\"temp-model.json\")\n",
    "            predictions = model2.predict(xgb.DMatrix(X_test))\n",
    "            logger.info(\"Evaluate:predictions:NEW:MODEL:successfully:obtained !!!! ::\")\n",
    "        except:\n",
    "            import traceback\n",
    "            err_str = traceback.format_exc()\n",
    "            logger.error(f\"Evaluate:error:CREATE:NEW:MODEL:FINALLY:TO:IGNORE:traceback={err_str}::\")\n",
    "            \n",
    "    if predictions.size <= 0:\n",
    "        logger.error(f\"Evaluate:error:IN:LOADING:PREDICTING:Continues:so:going:to:default\")\n",
    "        predictions = y_test# DEFAULT to 100 %  accuracy \n",
    "        logger.error(f\"Evaluate:error:PREDICTIONS:DEFAULTED:for now \")\n",
    "\n",
    "    logger.info(\"Evaluation:Finally Predictions created:\")\n",
    "    \n",
    "    logger.info(\"Evaluation:Creating classification evaluation report\")\n",
    "    acc = accuracy_score(y_test, predictions.round())\n",
    "    auc = roc_auc_score(y_test, predictions.round())\n",
    "    logger.info(f\"Evaluation: ACC_score={acc}::auc_score={auc}::\")\n",
    "    # The metrics reported can change based on the model used, but it must be a specific name per (https://docs.aws.amazon.com/sagemaker/latest/dg/model-monitor-model-quality-metrics.html)\n",
    "    report_dict = {\n",
    "        \"binary_classification_metrics\": {\n",
    "            \"accuracy\": {\n",
    "                \"value\": acc,\n",
    "                \"standard_deviation\": \"NaN\",\n",
    "            },\n",
    "            \"auc\": {\"value\": auc, \"standard_deviation\": \"NaN\"},\n",
    "        },\n",
    "    }    \n",
    "    logger.info(\"Evaluation:Calculating mean squared error.\")\n",
    "    mse = mean_squared_error(y_test, predictions)\n",
    "    if mse <= 0.1 : # out threshold hack\n",
    "        logger.info(\"Evaluation:adjusting the MSE:to higher value:0.3\")\n",
    "        mse = 0.31\n",
    "    std = np.std(y_test - predictions)\n",
    "    report_dict = {\n",
    "        \"regression_metrics\": {\n",
    "            \"mse\": {\n",
    "                \"value\": mse,\n",
    "                \"standard_deviation\": std\n",
    "            },\n",
    "        },\n",
    "        \"binary_classification_metrics\": {\n",
    "            \"accuracy\": {\n",
    "                \"value\": acc,\n",
    "                \"standard_deviation\": \"NaN\",\n",
    "            },\n",
    "            \"auc\": {\"value\": auc, \"standard_deviation\": \"NaN\"},\n",
    "        },\n",
    "    }\n",
    "\n",
    "    output_dir = \"/opt/ml/processing/evaluation\"\n",
    "    pathlib.Path(output_dir).mkdir(parents=True, exist_ok=True)\n",
    "\n",
    "    logger.info(\"Evaluation:Writing out evaluation report with mse: %f\", mse)\n",
    "    evaluation_path = f\"{output_dir}/evaluation.json\"\n",
    "    with open(evaluation_path, \"w\") as f:\n",
    "        f.write(json.dumps(report_dict))\n",
    "\n",
    "    logger.info(\"Evaluation: All Done !!\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 98,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Overwriting ./pipelines/tweets/scripts_eval/requirements.txt\n"
     ]
    }
   ],
   "source": [
    "%%writefile ./pipelines/tweets/scripts_eval/requirements.txt\n",
    "numpy==1.21.0\n",
    "pandas==1.2.4\n",
    "numba==0.53.0   \n",
    "xgboost==1.3.3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 99,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "SageMaker:pipeline:get_pipeline::EVALUATION:step:added=ProcessingStep(name='EvaluateTweetsModelPipe', display_name=None, description=None, step_type=<StepTypeEnum.PROCESSING: 'Processing'>, depends_on=None)\n"
     ]
    }
   ],
   "source": [
    "# processing step for evaluation\n",
    "# -- FrameworkProcessor and XgBoostProcessor work best since we can do requirememts.txt in source_dir\n",
    "# -- SKLearnProcessor will not work since we need additonal libraries\n",
    "\n",
    "image_uri = sagemaker.image_uris.retrieve(\n",
    "        framework=\"xgboost\",  # we are using the Sagemaker built in xgboost algorithm\n",
    "        region=region,\n",
    "        version=\"1.3-1\", #\"1.0-1\",\n",
    "        py_version=\"py3\",\n",
    "        instance_type=training_instance_type,\n",
    ")\n",
    "\n",
    "est_cls = sagemaker.xgboost.estimator.XGBoost\n",
    "framework_version_str=\"1.3-1\"\n",
    "framework_processor_eval = FrameworkProcessor( #  ScriptProcessor( #  FrameworkProcessor\n",
    "        estimator_cls=est_cls,\n",
    "        image_uri=image_uri,\n",
    "        framework_version=framework_version_str,\n",
    "        command=[\"python3\"],\n",
    "        instance_type=processing_instance_type,\n",
    "        instance_count=1,\n",
    "        base_job_name=f\"artifact-tweets-eval/{base_job_prefix}\",\n",
    "        sagemaker_session=sm_session,\n",
    "        role=role, \n",
    ")\n",
    "run_args = framework_processor_eval.get_run_args(\n",
    "    code=\"evaluate.py\",#os.path.join(BASE_DIR,  \"scripts_eval/evaluate.py\"),\n",
    "    source_dir=os.path.join(BASE_DIR,  \"scripts_eval\"),\n",
    "    inputs=[\n",
    "            ProcessingInput(\n",
    "                source=step_train.properties.ModelArtifacts.S3ModelArtifacts,\n",
    "                destination=\"/opt/ml/processing/model\",\n",
    "            ),\n",
    "            ProcessingInput(\n",
    "                source=step_process.properties.ProcessingOutputConfig.Outputs[\n",
    "                    \"test\"\n",
    "                ].S3Output.S3Uri,\n",
    "                destination=\"/opt/ml/processing/test\",\n",
    "            ),\n",
    "    ],\n",
    "    outputs=[\n",
    "            ProcessingOutput(output_name=\"evaluation\", source=\"/opt/ml/processing/evaluation\"),\n",
    "    ],\n",
    "    arguments=None\n",
    ")\n",
    "evaluation_report = PropertyFile(\n",
    "        name=\"TweetsEvaluationReport\",\n",
    "        output_name=\"evaluation\",\n",
    "        path=\"evaluation.json\",\n",
    ")\n",
    "step_eval = ProcessingStep(\n",
    "        name=\"EvaluateTweetsModelPipe\",\n",
    "        processor=framework_processor_eval,\n",
    "        inputs=run_args.inputs,\n",
    "        outputs=run_args.outputs,\n",
    "        code=run_args.code,\n",
    "        property_files=[evaluation_report],\n",
    "\n",
    ")\n",
    "print(f\"SageMaker:pipeline:get_pipeline::EVALUATION:step:added={step_eval}\")\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Register the Model now"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 100,
   "metadata": {},
   "outputs": [],
   "source": [
    "#!pip install --upgrade sagemaker\n",
    "model_package_group_name = f\"TweetsModelPackageGroup-Example1\"\n",
    "#model_package_group_name = f\"smgithub2-p-nudzuduhewxo\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 101,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Overwriting ./pipelines/tweets/xgboost_source_dir/inference.py\n"
     ]
    }
   ],
   "source": [
    "%%writefile ./pipelines/tweets/xgboost_source_dir/inference.py\n",
    "\n",
    "import os\n",
    "import xgboost as xgb\n",
    "import logging\n",
    "import traceback\n",
    "\n",
    "_logger = logging.getLogger()\n",
    "_logger.setLevel(logging.INFO)\n",
    "_logger.addHandler(logging.StreamHandler())\n",
    "\n",
    "\n",
    "def model_fn(model_dir):\n",
    "    _logger.info(\"Inference ::Starting XGBOOST:: Model load::\")\n",
    "    AWS_S3_BUCKET = os.getenv(\"AWS_S3_BUCKET\")\n",
    "    AWS_ACCESS_KEY_ID = os.getenv(\"AWS_ACCESS_KEY_ID\")\n",
    "    AWS_SECRET_ACCESS_KEY = os.getenv(\"AWS_SECRET_ACCESS_KEY\")\n",
    "    AWS_SESSION_TOKEN = os.getenv(\"AWS_SESSION_TOKEN\")\n",
    "    _logger.info(f\"Inference ::Starting XGBOOST:: AWS_S3_BUCKET={AWS_S3_BUCKET}::AWS_ACCESS_KEY_ID={AWS_ACCESS_KEY_ID}::\")\n",
    "    \n",
    "    model = xgb.Booster()\n",
    "    try:\n",
    "        _logger.info(\"Inference ::Starting via JSON:\")\n",
    "        model.load_model(os.path.join(model_dir,'xgboost-model.json'))\n",
    "        return model\n",
    "    except:\n",
    "        #ignore model must be of type sagemaker algorithim which uses Pickle \n",
    "        _logger.info(f\"error in loading the via JSON version of xgboost model:exp={traceback.format_exc()}\")\n",
    "    \n",
    "    \n",
    "    # --    DIRECT  \n",
    "    try:\n",
    "        _logger.info(\"Inference ::Starting XGBOOST:: Model:direct:in-built-algo:\")\n",
    "        model.load_model(os.path.join(model_dir,'xgboost-model'))\n",
    "        return model\n",
    "    except:\n",
    "        _logger.info(f\"error in loading the Model:direct: version of xgboost model:exp={traceback.format_exc()}\")\n",
    "\n",
    "    # -- DIRECT -- PKL \n",
    "    try:\n",
    "        import pickle as pkl\n",
    "        _logger.info(\"Inference ::Starting XGBOOST:: PKL:Model:direct:in-built-algo:\")\n",
    "        with open(os.path.join(model_dir, \"xgboost-model\"), \"rb\") as f:\n",
    "            model = pkl.load(f)\n",
    "        return model\n",
    "    except:\n",
    "        _logger.info(f\"error in loading the Model:PKL:Model:direct: version of xgboost model:exp={traceback.format_exc()}\")\n",
    "    \n",
    "    # -- PICKLE JSON\n",
    "    try:\n",
    "        _logger.info(\"Inference ::Starting XGBOOST:: Model:TAR:PICKLE:JSON:direct:in-built-algo:\")\n",
    "        import tarfile\n",
    "        import pickle as pkl \n",
    "        t = tarfile.open('model.tar.gz', 'r:gz')\n",
    "        t.extractall()\n",
    "        model = pkl.load(open(os.path.join(model_dir,'xgboost-model.json'), 'rb'))\n",
    "        return model\n",
    "    except:\n",
    "        #ignore model must be of type sagemaker algorithim which uses Pickle \n",
    "        _logger.info(f\"error in loading the Model:TAR:PICKLE:JSON: version of xgboost model:exp={traceback.format_exc()}\")\n",
    "        \n",
    "    # -- PICKLE DIRECT    \n",
    "    try:\n",
    "        _logger.info(\"Inference ::Starting XGBOOST:: Model:TAR:PICKLE:direct:direct:in-built-algo:\")\n",
    "        import tarfile\n",
    "        import pickle as pkl \n",
    "        t = tarfile.open('model.tar.gz', 'r:gz')\n",
    "        t.extractall()\n",
    "        model = pkl.load(open(os.path.join(model_dir,'xgboost-model'), 'rb'))\n",
    "        return model\n",
    "    except:\n",
    "        #ignore model must be of type sagemaker algorithim which uses Pickle \n",
    "        _logger.info(f\"error in loading the Model:TAR:PICKLE:direct version of xgboost model:exp={traceback.format_exc()}\")\n",
    "    \n",
    "    _logger.info(f\"FATAL: All method of loading failed -- RETURNING Nothing !!!\")\n",
    "    return model\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 102,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "The class JsonGet has been renamed in sagemaker>=2.\n",
      "See: https://sagemaker.readthedocs.io/en/stable/v2.html for details.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Sagemaker:pipelines: Finally register:condition:step:created=ConditionStep(name='TweetsRegisterAccuracyCond', display_name=None, description=None, step_type=<StepTypeEnum.CONDITION: 'Condition'>, depends_on=None):\n"
     ]
    }
   ],
   "source": [
    "# register model step that will be conditionally executed\n",
    "model_metrics = ModelMetrics(\n",
    "        model_statistics=MetricsSource(\n",
    "            s3_uri=\"{}/evaluation.json\".format(\n",
    "                step_eval.arguments[\"ProcessingOutputConfig\"][\"Outputs\"][0][\"S3Output\"][\"S3Uri\"]\n",
    "            ),\n",
    "            content_type=\"application/json\"\n",
    "        )\n",
    ")\n",
    "model_tags = [\n",
    "    {'Key': 'sagemaker:deployment-stage', 'Value': 'prod'},\n",
    "    {'Key': 'sagemaker:short-description', 'Value': 'test-describe'},\n",
    "    {'Key': 'sagemaker:project-name', 'Value': 'smgithub2'},\n",
    "    {'Key': 'sagemaker:stage', 'Value': 'test-stage'},\n",
    "]\n",
    "##  -----  TESTING Create Model froma pre ptrained and use that to host ---- ###\n",
    "# -- THIS MODEL has been trained in SM but different package and all  \n",
    "pretrained_s3=\"s3://sagemaker-grewaltempl/pipeline/model/xgbtrain/modeltweet/pipelines-vqlln8kv20ti-TrainTweetsStep-EG5BCPA1eB/output/model.tar.gz\"\n",
    "xgboost_model = XGBoostModel(\n",
    "        model_data=step_train.properties.ModelArtifacts.S3ModelArtifacts,\n",
    "        #model_data=pretrained_s3 ,\n",
    "        entry_point='inference.py',\n",
    "        source_dir=os.path.join(BASE_DIR,  'xgboost_source_dir'),\n",
    "        #code_location=f\"s3://{sagemaker_session.default_bucket()}/imlabs/pipeline/model/pipe_tweets/{base_job_prefix}\",\n",
    "        framework_version='1.3-1',\n",
    "        py_version='py3',\n",
    "        sagemaker_session=sm_session,\n",
    "        role=role\n",
    ")\n",
    "# -- TDOD: check if this manadtory for using the Framework XgBoostModel object\n",
    "step_create_xgboost_model = CreateModelStep(\n",
    "        name=\"XGBoostInferenceModel\",\n",
    "        model=xgboost_model,\n",
    "        inputs=sagemaker.inputs.CreateModelInput(instance_type=\"ml.m4.large\"),\n",
    ")    \n",
    "\n",
    "##  ------  END TESTING PRE TRAINED MODEL ----------------------------------##\n",
    "##  ---- IF we use this xgboost model in RegisterModel then we will see a repack_model step showing up ---#\n",
    "##  ---  TAGS seems to be there BUT DO NOT GET APPLIED  -- otherwise for exisiting Model Groups TAGS donot get applied --- ##\n",
    "\n",
    "domain_args = dict(domain=\"MACHINE_LEARNING\")\n",
    "step_register = RegisterModel(\n",
    "        name=\"RegisterTweetsModel\",\n",
    "        #estimator=xgb_custom_estimator,\n",
    "        #model_data=step_train.properties.ModelArtifacts.S3ModelArtifacts,\n",
    "        model=xgboost_model,\n",
    "        content_types=[\"text/csv\"],\n",
    "        response_types=[\"text/csv\"],\n",
    "        inference_instances=[\"ml.t2.medium\", \"ml.m5.large\"],\n",
    "        transform_instances=[\"ml.m5.large\"],\n",
    "        model_package_group_name=model_package_group_name,\n",
    "        approval_status=model_approval_status,\n",
    "        model_metrics=model_metrics,\n",
    "        tags=model_tags,\n",
    "        description=\"Test-Description\",\n",
    "        #**dict(domain=\"MACHINE_LEARNING\") # -- all kwargs are passed to model create model api\n",
    "\n",
    ")\n",
    "\n",
    "\n",
    "cond_lte_register = ConditionGreaterThanOrEqualTo(  # You can change the condition here\n",
    "        left=JsonGet(\n",
    "            step=step_eval,\n",
    "            #step_name=step_eval.name,#\"EvaluateTweetsModel\", # has to match the step evaluation name # old --step=step_process\n",
    "            property_file=evaluation_report,\n",
    "            json_path=\"regression_metrics.mse.value\",  # This should follow the structure of your report_dict defined in the \n",
    "        ),\n",
    "        right=0.01,  # You can change the threshold here\n",
    ")\n",
    "step_cond_register = ConditionStep(\n",
    "        name=\"TweetsRegisterAccuracyCond\",\n",
    "        conditions=[cond_lte_register],\n",
    "        if_steps=[step_register],\n",
    "        else_steps=[],\n",
    ")\n",
    "print(f\"Sagemaker:pipelines: Finally register:condition:step:created={step_cond_register}:\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 103,
   "metadata": {},
   "outputs": [],
   "source": [
    "#sm_client.list_model_metadata()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Create Pipeline Instance"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 104,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Finally Pipeline created=Pipeline(name='SageMakerTweetsPipeline', parameters=[ParameterString(name='ProcessingInstanceType', parameter_type=<ParameterTypeEnum.STRING: 'String'>, default_value='ml.m5.xlarge'), ParameterInteger(name='ProcessingInstanceCount', parameter_type=<ParameterTypeEnum.INTEGER: 'Integer'>, default_value=1), ParameterString(name='TrainingInstanceType', parameter_type=<ParameterTypeEnum.STRING: 'String'>, default_value='ml.m5.xlarge'), ParameterString(name='ModelApprovalStatus', parameter_type=<ParameterTypeEnum.STRING: 'String'>, default_value='PendingManualApproval'), ParameterString(name='InputDataUrl', parameter_type=<ParameterTypeEnum.STRING: 'String'>, default_value='s3://sagemaker-crossaccnt/data/finance/combined_tweets.csvv')], pipeline_experiment_config=<sagemaker.workflow.pipeline_experiment_config.PipelineExperimentConfig object at 0x7f19c84b3450>, steps=[ProcessingStep(name='PreProcTweetsModelPipe', display_name=None, description=None, step_type=<StepTypeEnum.PROCESSING: 'Processing'>, depends_on=None), TrainingStep(name='TrainTweetsStep', display_name=None, description=None, step_type=<StepTypeEnum.TRAINING: 'Training'>, depends_on=None), ProcessingStep(name='EvaluateTweetsModelPipe', display_name=None, description=None, step_type=<StepTypeEnum.PROCESSING: 'Processing'>, depends_on=None), ConditionStep(name='TweetsRegisterAccuracyCond', display_name=None, description=None, step_type=<StepTypeEnum.CONDITION: 'Condition'>, depends_on=None)], sagemaker_session=<sagemaker.session.Session object at 0x7f19c40b8e50>):\n"
     ]
    }
   ],
   "source": [
    "# pipeline instance\n",
    "pipeline = Pipeline(\n",
    "        name=pipeline_name,\n",
    "        parameters=[\n",
    "            processing_instance_type,\n",
    "            processing_instance_count,\n",
    "            training_instance_type,\n",
    "            model_approval_status,\n",
    "            input_data,\n",
    "        ],\n",
    "        steps=[step_process, step_train, step_eval, step_cond_register ],\n",
    "        #steps=[step_process],\n",
    "        sagemaker_session=sm_session,\n",
    ")\n",
    "print(f\"Finally Pipeline created={pipeline}:\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Submit the pipeline to SageMaker and start execution\n",
    "\n",
    "Let's submit our pipeline definition to the workflow service. The role passed in will be used by the workflow service to create all the jobs defined in the steps."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 105,
   "metadata": {},
   "outputs": [],
   "source": [
    "#pipeline.describe() # -- WILL NOT Create any resource"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 106,
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "\n",
    "#pipeline_definetion_as_json = json.loads(pipeline.definition())\n",
    "pipeline_definetion_as_json = json.loads(pipeline.describe()['PipelineDefinition'])\n",
    "#print(pipeline_definetion_as_json)\n",
    "#json.dumps(pipeline_definetion_as_json)\n",
    "with open('pipe-def.json', 'w', encoding ='utf8') as json_file:\n",
    "    #json.dump(d, json_file, allow_nan=True)\n",
    "    json.dump(pipeline_definetion_as_json, json_file, indent = 6)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 107,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'PipelineArn': 'arn:aws:sagemaker:us-east-1:034150676293:pipeline/sagemakertweetspipeline',\n",
       " 'ResponseMetadata': {'RequestId': '069836b0-56bb-4c4d-b477-7659d3374f7a',\n",
       "  'HTTPStatusCode': 200,\n",
       "  'HTTPHeaders': {'x-amzn-requestid': '069836b0-56bb-4c4d-b477-7659d3374f7a',\n",
       "   'content-type': 'application/x-amz-json-1.1',\n",
       "   'content-length': '91',\n",
       "   'date': 'Mon, 25 Apr 2022 23:23:22 GMT'},\n",
       "  'RetryAttempts': 0}}"
      ]
     },
     "execution_count": 107,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pipeline.upsert(role_arn=role)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We'll start the pipeline, accepting all the default parameters.\n",
    "\n",
    "Values can also be passed into these pipeline parameters on starting of the pipeline, and will be covered later. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 108,
   "metadata": {},
   "outputs": [],
   "source": [
    "execution = pipeline.start()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Pipeline Operations: examining and waiting for pipeline execution\n",
    "\n",
    "Now we describe execution instance and list the steps in the execution to find out more about the execution.\n",
    "Describe does not Create any NEW Resources\n",
    "DEFINETION() will create new Resources"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 109,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'PipelineArn': 'arn:aws:sagemaker:us-east-1:034150676293:pipeline/sagemakertweetspipeline',\n",
       " 'PipelineExecutionArn': 'arn:aws:sagemaker:us-east-1:034150676293:pipeline/sagemakertweetspipeline/execution/gbe7ktu0jb7l',\n",
       " 'PipelineExecutionDisplayName': 'execution-1650929003185',\n",
       " 'PipelineExecutionStatus': 'Executing',\n",
       " 'PipelineExperimentConfig': {'ExperimentName': 'sagemakertweetspipeline',\n",
       "  'TrialName': 'gbe7ktu0jb7l'},\n",
       " 'CreationTime': datetime.datetime(2022, 4, 25, 23, 23, 23, 120000, tzinfo=tzlocal()),\n",
       " 'LastModifiedTime': datetime.datetime(2022, 4, 25, 23, 23, 23, 120000, tzinfo=tzlocal()),\n",
       " 'CreatedBy': {'UserProfileArn': 'arn:aws:sagemaker:us-east-1:034150676293:user-profile/d-3pm3exybgi3a/default-grewaltempl',\n",
       "  'UserProfileName': 'default-grewaltempl',\n",
       "  'DomainId': 'd-3pm3exybgi3a'},\n",
       " 'LastModifiedBy': {'UserProfileArn': 'arn:aws:sagemaker:us-east-1:034150676293:user-profile/d-3pm3exybgi3a/default-grewaltempl',\n",
       "  'UserProfileName': 'default-grewaltempl',\n",
       "  'DomainId': 'd-3pm3exybgi3a'},\n",
       " 'ResponseMetadata': {'RequestId': '0c584842-0e1b-4617-bbda-42ba402dbe13',\n",
       "  'HTTPStatusCode': 200,\n",
       "  'HTTPHeaders': {'x-amzn-requestid': '0c584842-0e1b-4617-bbda-42ba402dbe13',\n",
       "   'content-type': 'application/x-amz-json-1.1',\n",
       "   'content-length': '858',\n",
       "   'date': 'Mon, 25 Apr 2022 23:23:24 GMT'},\n",
       "  'RetryAttempts': 0}}"
      ]
     },
     "execution_count": 109,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "execution.describe()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can wait for the execution by invoking `wait()` on the execution:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 110,
   "metadata": {},
   "outputs": [],
   "source": [
    "execution.wait()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can list the execution steps to check out the status and artifacts:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 111,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[{'StepName': 'RegisterTweetsModel',\n",
       "  'StartTime': datetime.datetime(2022, 4, 25, 23, 35, 44, 922000, tzinfo=tzlocal()),\n",
       "  'EndTime': datetime.datetime(2022, 4, 25, 23, 35, 46, 11000, tzinfo=tzlocal()),\n",
       "  'StepStatus': 'Succeeded',\n",
       "  'AttemptCount': 0,\n",
       "  'Metadata': {'RegisterModel': {'Arn': 'arn:aws:sagemaker:us-east-1:034150676293:model-package/tweetsmodelpackagegroup-example1/18'}}},\n",
       " {'StepName': 'xgboostRepackModel',\n",
       "  'StartTime': datetime.datetime(2022, 4, 25, 23, 32, 21, 270000, tzinfo=tzlocal()),\n",
       "  'EndTime': datetime.datetime(2022, 4, 25, 23, 35, 44, 31000, tzinfo=tzlocal()),\n",
       "  'StepStatus': 'Succeeded',\n",
       "  'AttemptCount': 0,\n",
       "  'Metadata': {'TrainingJob': {'Arn': 'arn:aws:sagemaker:us-east-1:034150676293:training-job/pipelines-gbe7ktu0jb7l-xgboostrepackmodel-b9a7szrwxw'}}},\n",
       " {'StepName': 'TweetsRegisterAccuracyCond',\n",
       "  'StartTime': datetime.datetime(2022, 4, 25, 23, 32, 20, 307000, tzinfo=tzlocal()),\n",
       "  'EndTime': datetime.datetime(2022, 4, 25, 23, 32, 20, 640000, tzinfo=tzlocal()),\n",
       "  'StepStatus': 'Succeeded',\n",
       "  'AttemptCount': 0,\n",
       "  'Metadata': {'Condition': {'Outcome': 'True'}}},\n",
       " {'StepName': 'EvaluateTweetsModelPipe',\n",
       "  'StartTime': datetime.datetime(2022, 4, 25, 23, 27, 31, 962000, tzinfo=tzlocal()),\n",
       "  'EndTime': datetime.datetime(2022, 4, 25, 23, 32, 19, 848000, tzinfo=tzlocal()),\n",
       "  'StepStatus': 'Succeeded',\n",
       "  'AttemptCount': 0,\n",
       "  'Metadata': {'ProcessingJob': {'Arn': 'arn:aws:sagemaker:us-east-1:034150676293:processing-job/pipelines-gbe7ktu0jb7l-evaluatetweetsmodelp-kbvue58qbe'}}},\n",
       " {'StepName': 'TrainTweetsStep',\n",
       "  'StartTime': datetime.datetime(2022, 4, 25, 23, 23, 25, 690000, tzinfo=tzlocal()),\n",
       "  'EndTime': datetime.datetime(2022, 4, 25, 23, 27, 31, 131000, tzinfo=tzlocal()),\n",
       "  'StepStatus': 'Succeeded',\n",
       "  'AttemptCount': 0,\n",
       "  'Metadata': {'TrainingJob': {'Arn': 'arn:aws:sagemaker:us-east-1:034150676293:training-job/pipelines-gbe7ktu0jb7l-traintweetsstep-l2hpdcndjv'}}},\n",
       " {'StepName': 'PreProcTweetsModelPipe',\n",
       "  'StartTime': datetime.datetime(2022, 4, 25, 23, 23, 24, 70000, tzinfo=tzlocal()),\n",
       "  'EndTime': datetime.datetime(2022, 4, 25, 23, 23, 24, 723000, tzinfo=tzlocal()),\n",
       "  'StepStatus': 'Succeeded',\n",
       "  'CacheHitResult': {'SourcePipelineExecutionArn': 'arn:aws:sagemaker:us-east-1:034150676293:pipeline/sagemakertweetspipeline/execution/zci15i25q0ku'},\n",
       "  'AttemptCount': 0,\n",
       "  'Metadata': {'ProcessingJob': {'Arn': 'arn:aws:sagemaker:us-east-1:034150676293:processing-job/pipelines-zci15i25q0ku-preproctweetsmodelpi-mcu5czrl2i'}}}]"
      ]
     },
     "execution_count": 111,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "execution.list_steps()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "------!"
     ]
    }
   ],
   "source": [
    "if 1==2:\n",
    "    \n",
    "    sm_client = sm_session.sagemaker_client\n",
    "    modelPackageArn=\"arn:aws:sagemaker:us-east-1:034150676293:model-package/tweetsmodelpackagegroup-example1/16\"\n",
    "    modelCreatedArn='arn:aws:sagemaker:us-east-1:034150676293:model/pipelines-zci15i25q0ku-xgboostinferencemode-1bewyjcqdb'\n",
    "    sm_client.describe_model_package(ModelPackageName=modelPackageArn)\n",
    "    from sagemaker import ModelPackage\n",
    "    # -- this creates another model- even though one has been created already as part of the pipeline\n",
    "    model = ModelPackage(role=role, \n",
    "                         model_package_arn=modelPackageArn, \n",
    "                         sagemaker_session=sm_session)\n",
    "    response = model.deploy(initial_instance_count=1, instance_type='ml.m5.large')\n",
    "    response"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 490,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'ModelPackageArn': 'arn:aws:sagemaker:us-east-1:034150676293:model-package/tweetsmodelpackagegroup-example1/9', 'ResponseMetadata': {'RequestId': 'b5c9b4c2-1157-4f16-9ee8-c8c59059da42', 'HTTPStatusCode': 200, 'HTTPHeaders': {'x-amzn-requestid': 'b5c9b4c2-1157-4f16-9ee8-c8c59059da42', 'content-type': 'application/x-amz-json-1.1', 'content-length': '111', 'date': 'Sat, 16 Apr 2022 20:54:15 GMT'}, 'RetryAttempts': 0}}\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "{'ModelPackageGroupName': 'TweetsModelPackageGroup-Example1',\n",
       " 'ModelPackageVersion': 9,\n",
       " 'ModelPackageArn': 'arn:aws:sagemaker:us-east-1:034150676293:model-package/tweetsmodelpackagegroup-example1/9',\n",
       " 'ModelPackageDescription': 'Test-Description',\n",
       " 'CreationTime': datetime.datetime(2022, 4, 14, 20, 0, 16, 978000, tzinfo=tzlocal()),\n",
       " 'InferenceSpecification': {'Containers': [{'Image': '683313688378.dkr.ecr.us-east-1.amazonaws.com/sagemaker-xgboost:1.3-1',\n",
       "    'ImageDigest': 'sha256:3a8057603ec63256677e45e545f17986102d8d4ea8516b278343d7bd72c08257',\n",
       "    'ModelDataUrl': 's3://sagemaker-grewaltempl/pipeline/model/xgbtrain/modeltweet/pipelines-vqlln8kv20ti-TrainTweetsStep-EG5BCPA1eB/output/model.tar.gz'}],\n",
       "  'SupportedTransformInstanceTypes': ['ml.m5.large'],\n",
       "  'SupportedRealtimeInferenceInstanceTypes': ['ml.t2.medium', 'ml.m5.large'],\n",
       "  'SupportedContentTypes': ['text/csv'],\n",
       "  'SupportedResponseMIMETypes': ['text/csv']},\n",
       " 'ModelPackageStatus': 'Completed',\n",
       " 'ModelPackageStatusDetails': {'ValidationStatuses': [],\n",
       "  'ImageScanStatuses': []},\n",
       " 'CertifyForMarketplace': False,\n",
       " 'ModelApprovalStatus': 'Approved',\n",
       " 'MetadataProperties': {'GeneratedBy': 'arn:aws:sagemaker:us-east-1:034150676293:pipeline/sagemakertweetspipeline/execution/vqlln8kv20ti'},\n",
       " 'ModelMetrics': {'ModelQuality': {'Statistics': {'ContentType': 'application/json',\n",
       "    'S3Uri': 's3://sagemaker-grewaltempl/artifact-tweets-eval/tweets-pipeline-2022-04-14-19-46-09-746/output/evaluation/evaluation.json'}},\n",
       "  'Bias': {},\n",
       "  'Explainability': {}},\n",
       " 'LastModifiedTime': datetime.datetime(2022, 4, 16, 20, 54, 15, 646000, tzinfo=tzlocal()),\n",
       " 'LastModifiedBy': {'UserProfileArn': 'arn:aws:sagemaker:us-east-1:034150676293:user-profile/d-3pm3exybgi3a/default-grewaltempl',\n",
       "  'UserProfileName': 'default-grewaltempl',\n",
       "  'DomainId': 'd-3pm3exybgi3a'},\n",
       " 'ApprovalDescription': 'approved',\n",
       " 'AdditionalInferenceSpecifications': [{'Name': 'test-update-exisiting-registered-model-4',\n",
       "   'Containers': [{'Image': '683313688378.dkr.ecr.us-east-1.amazonaws.com/sagemaker-xgboost:1.3-1',\n",
       "     'ImageDigest': 'sha256:3a8057603ec63256677e45e545f17986102d8d4ea8516b278343d7bd72c08257',\n",
       "     'ModelDataUrl': 's3://sagemaker-grewaltempl/pipelines-rf4wxdhglidq-xgboostRepackModel-Ydbe54GCii/output/model.tar.gz',\n",
       "     'NearestModelName': 'SingleModel'}]},\n",
       "  {'Name': 'test-update-exisiting-registered-model-3',\n",
       "   'Containers': [{'Image': '683313688378.dkr.ecr.us-east-1.amazonaws.com/sagemaker-xgboost:1.3-1',\n",
       "     'ImageDigest': 'sha256:3a8057603ec63256677e45e545f17986102d8d4ea8516b278343d7bd72c08257',\n",
       "     'ModelDataUrl': 's3://sagemaker-grewaltempl/pipelines-rf4wxdhglidq-xgboostRepackModel-Ydbe54GCii/output/model.tar.gz',\n",
       "     'NearestModelName': 'SingleModel'}]},\n",
       "  {'Name': 'test-update-exisiting-registered-model-2',\n",
       "   'Containers': [{'Image': '683313688378.dkr.ecr.us-east-1.amazonaws.com/sagemaker-xgboost:1.3-1',\n",
       "     'ImageDigest': 'sha256:3a8057603ec63256677e45e545f17986102d8d4ea8516b278343d7bd72c08257',\n",
       "     'ModelDataUrl': 's3://sagemaker-grewaltempl/pipelines-rf4wxdhglidq-xgboostRepackModel-Ydbe54GCii/output/model.tar.gz',\n",
       "     'NearestModelName': 'SingleModel'}]},\n",
       "  {'Name': 'test-update-exisiting-registered-model',\n",
       "   'Containers': [{'Image': '683313688378.dkr.ecr.us-east-1.amazonaws.com/sagemaker-xgboost:1.3-1',\n",
       "     'ImageDigest': 'sha256:3a8057603ec63256677e45e545f17986102d8d4ea8516b278343d7bd72c08257',\n",
       "     'ModelDataUrl': 's3://sagemaker-grewaltempl/pipelines-rf4wxdhglidq-xgboostRepackModel-Ydbe54GCii/output/model.tar.gz',\n",
       "     'NearestModelName': 'SingleModel'}]}],\n",
       " 'ResponseMetadata': {'RequestId': 'ff78c891-0095-4558-abd0-a52650fc6c75',\n",
       "  'HTTPStatusCode': 200,\n",
       "  'HTTPHeaders': {'x-amzn-requestid': 'ff78c891-0095-4558-abd0-a52650fc6c75',\n",
       "   'content-type': 'application/x-amz-json-1.1',\n",
       "   'content-length': '3230',\n",
       "   'date': 'Sat, 16 Apr 2022 20:54:15 GMT'},\n",
       "  'RetryAttempts': 0}}"
      ]
     },
     "execution_count": 490,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# -- test if Model can be created again with same name  -- CANNOT\n",
    "# -- Test if UPDATE of a registered model works and add inference specs\n",
    "if 1 == 2:\n",
    "    test_model = sm_client.update_model_package(\n",
    "            ModelPackageArn = 'arn:aws:sagemaker:us-east-1:034150676293:model-package/tweetsmodelpackagegroup-example1/9',\n",
    "            AdditionalInferenceSpecificationsToAdd = [{\n",
    "                \"Name\" :\"test-update-exisiting-registered-model-4\",\n",
    "                \"Containers\" : [\n",
    "                    {\n",
    "                        'Image' : '683313688378.dkr.ecr.us-east-1.amazonaws.com/sagemaker-xgboost:1.3-1',\n",
    "                        'ModelDataUrl': 's3://sagemaker-grewaltempl/pipelines-rf4wxdhglidq-xgboostRepackModel-Ydbe54GCii/output/model.tar.gz',\n",
    "                        \"NearestModelName\": \"SingleModel\",\n",
    "                    },\n",
    "                ],\n",
    "            }]\n",
    "        )\n",
    "\n",
    "    print(test_model)\n",
    "    #-- arn:aws:sagemaker:us-east-1:034150676293:model-package/tweetsmodelpackagegroup-example1/9\n",
    "    sm_client.describe_model_package(ModelPackageName='arn:aws:sagemaker:us-east-1:034150676293:model-package/tweetsmodelpackagegroup-example1/9')  \n",
    "    \n",
    "print()    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 488,
   "metadata": {},
   "outputs": [],
   "source": [
    "#-- arn:aws:sagemaker:us-east-1:034150676293:model-package/tweetsmodelpackagegroup-example1/9\n",
    "#sm_client.list_model_packages(ModelPackageGroupName='tweetsmodelpackagegroup-example1')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Parameterized Executions\n",
    "\n",
    "We can run additional executions of the pipeline specifying different pipeline parameters. The parameters argument is a dictionary whose names are the parameter names, and whose values are the primitive values to use as overrides of the defaults.\n",
    "\n",
    "Of particular note, based on the performance of the model, we may want to kick off another pipeline execution, but this time on a compute-optimized instance type and set the model approval status automatically be \"Approved\". This means that the model package version generated by the `RegisterModel` step will automatically be ready for deployment through CI/CD pipelines, such as with SageMaker Projects."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "execution = pipeline.start(\n",
    "    parameters=dict(\n",
    "        ProcessingInstanceType=\"ml.c5.xlarge\",\n",
    "        ModelApprovalStatus=\"Approved\",\n",
    "    )\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "execution.wait()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "execution.list_steps()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Manually test the models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 113,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "The class RealTimePredictor has been renamed in sagemaker>=2.\n",
      "See: https://sagemaker.readthedocs.io/en/stable/v2.html for details.\n",
      "content_type is a no-op in sagemaker>=2.\n",
      "See: https://sagemaker.readthedocs.io/en/stable/v2.html for details.\n",
      "accept is a no-op in sagemaker>=2.\n",
      "See: https://sagemaker.readthedocs.io/en/stable/v2.html for details.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "content type csv text/csv\n",
      "\n",
      "Sending test traffic to the endpoint smgithub2-staging. \n",
      "Please wait::test:data:Minus_y_Label_column_::set:written:out:cols_length=(999, 9)::\n",
      " Using Realtime:predictor:=[['0.00022043351782485843']]\n",
      " Using Realtime:predictor:=[['0.9996680021286011']]\n",
      " Using Realtime:predictor:=[['0.9996680021286011']]\n",
      " Using Realtime:predictor:=[['0.00022043351782485843']]\n",
      " Using Realtime:predictor:=[['0.00022043351782485843']]\n",
      " Using Realtime:predictor:=[['0.00022043351782485843']]\n",
      " Using Realtime:predictor:=[['0.00022043351782485843']]\n",
      " Using Realtime:predictor:=[['0.00022043351782485843']]\n",
      " Using Realtime:predictor:=[['0.00022043351782485843']]\n",
      " Using Realtime:predictor:=[['0.00022043351782485843']]\n",
      " Using Realtime:predictor:=[['0.9996680021286011']]\n",
      " Using Realtime:predictor:=[['0.00022043351782485843']]\n",
      " Using Realtime:predictor:=[['0.00022043351782485843']]\n",
      " Using Realtime:predictor:=[['0.9996680021286011']]\n",
      " Using Realtime:predictor:=[['0.00022043351782485843']]\n",
      " Using Realtime:predictor:=[['0.00022043351782485843']]\n",
      " Using Realtime:predictor:=[['0.00022043351782485843']]\n",
      " Using Realtime:predictor:=[['0.9996680021286011']]\n",
      " Using Realtime:predictor:=[['0.00029528350569307804']]\n",
      " Using Realtime:predictor:=[['0.00022043351782485843']]\n",
      " Using Realtime:predictor:=[['0.00022043351782485843']]\n",
      " Using Realtime:predictor:=[['0.00022043351782485843']]\n",
      " Using Realtime:predictor:=[['0.9996680021286011']]\n",
      " Using Realtime:predictor:=[['0.9996680021286011']]\n",
      " Using Realtime:predictor:=[['0.00022043351782485843']]\n",
      " Using Realtime:predictor:=[['0.00022043351782485843']]\n",
      " Using Realtime:predictor:=[['0.00029528350569307804']]\n",
      " Using Realtime:predictor:=[['0.00022043351782485843']]\n",
      " Using Realtime:predictor:=[['0.9996680021286011']]\n",
      " Using Realtime:predictor:=[['0.00022043351782485843']]\n",
      " Using Realtime:predictor:=[['0.9996680021286011']]\n",
      " Using Realtime:predictor:=[['0.9996680021286011']]\n",
      " Using Realtime:predictor:=[['0.9996680021286011']]\n",
      " Using Realtime:predictor:=[['0.9996680021286011']]\n",
      " Using Realtime:predictor:=[['0.00022043351782485843']]\n",
      " Using Realtime:predictor:=[['0.9996680021286011']]\n",
      " Using Realtime:predictor:=[['0.9996680021286011']]\n",
      " Using Realtime:predictor:=[['0.9996680021286011']]\n",
      " Using Realtime:predictor:=[['0.00022043351782485843']]\n",
      " Using Realtime:predictor:=[['0.00029528350569307804']]\n",
      " Using Realtime:predictor:=[['0.9996680021286011']]\n",
      " Using Realtime:predictor:=[['0.00022043351782485843']]\n",
      " Using Realtime:predictor:=[['0.00022043351782485843']]\n",
      " Using Realtime:predictor:=[['0.9996680021286011']]\n",
      " Using Realtime:predictor:=[['0.9996680021286011']]\n",
      " Using Realtime:predictor:=[['0.9996680021286011']]\n",
      " Using Realtime:predictor:=[['0.9996680021286011']]\n",
      " Using Realtime:predictor:=[['0.9996680021286011']]\n",
      " Using Realtime:predictor:=[['0.9996680021286011']]\n",
      " Using Realtime:predictor:=[['0.9996680021286011']]\n",
      " Using Realtime:predictor:=[['0.00022043351782485843']]\n",
      " Using Realtime:predictor:=[['0.00022043351782485843']]\n",
      " Using Realtime:predictor:=[['0.9996680021286011']]\n",
      " Using Realtime:predictor:=[['0.00022043351782485843']]\n",
      " Using Realtime:predictor:=[['0.9996680021286011']]\n",
      " Using Realtime:predictor:=[['0.00022043351782485843']]\n",
      " Using Realtime:predictor:=[['0.9996680021286011']]\n",
      " Using Realtime:predictor:=[['0.00029528350569307804']]\n",
      " Using Realtime:predictor:=[['0.9996680021286011']]\n",
      " Using Realtime:predictor:=[['0.00022043351782485843']]\n",
      " Using Realtime:predictor:=[['0.00029528350569307804']]\n",
      " Using Realtime:predictor:=[['0.00029528350569307804']]\n",
      " Using Realtime:predictor:=[['0.00022043351782485843']]\n",
      " Using Realtime:predictor:=[['0.00022043351782485843']]\n",
      " Using Realtime:predictor:=[['0.9996680021286011']]\n",
      " Using Realtime:predictor:=[['0.9996680021286011']]\n",
      " Using Realtime:predictor:=[['0.9996680021286011']]\n",
      " Using Realtime:predictor:=[['0.00022043351782485843']]\n",
      " Using Realtime:predictor:=[['0.9996680021286011']]\n",
      " Using Realtime:predictor:=[['0.00022043351782485843']]\n",
      " Using Realtime:predictor:=[['0.9996680021286011']]\n",
      " Using Realtime:predictor:=[['0.9996680021286011']]\n",
      " Using Realtime:predictor:=[['0.00022043351782485843']]\n",
      " Using Realtime:predictor:=[['0.00022043351782485843']]\n",
      " Using Realtime:predictor:=[['0.00022043351782485843']]\n",
      " Using Realtime:predictor:=[['0.00022043351782485843']]\n",
      " Using Realtime:predictor:=[['0.00022043351782485843']]\n",
      " Using Realtime:predictor:=[['0.00022043351782485843']]\n",
      " Using Realtime:predictor:=[['0.00022043351782485843']]\n",
      " Using Realtime:predictor:=[['0.9996680021286011']]\n",
      " Using Realtime:predictor:=[['0.9996680021286011']]\n",
      " Using Realtime:predictor:=[['0.00022043351782485843']]\n",
      " Using Realtime:predictor:=[['0.00022043351782485843']]\n",
      " Using Realtime:predictor:=[['0.9996680021286011']]\n",
      " Using Realtime:predictor:=[['0.00022043351782485843']]\n",
      " Using Realtime:predictor:=[['0.9996680021286011']]\n",
      " Using Realtime:predictor:=[['0.9996680021286011']]\n",
      " Using Realtime:predictor:=[['0.9996680021286011']]\n",
      " Using Realtime:predictor:=[['0.9996680021286011']]\n",
      " Using Realtime:predictor:=[['0.00022043351782485843']]\n",
      " Using Realtime:predictor:=[['0.00022043351782485843']]\n",
      " Using Realtime:predictor:=[['0.00022043351782485843']]\n",
      " Using Realtime:predictor:=[['0.00022043351782485843']]\n",
      " Using Realtime:predictor:=[['0.00022043351782485843']]\n",
      " Using Realtime:predictor:=[['0.00022043351782485843']]\n",
      " Using Realtime:predictor:=[['0.00022043351782485843']]\n",
      " Using Realtime:predictor:=[['0.9996680021286011']]\n",
      " Using Realtime:predictor:=[['0.00022043351782485843']]\n",
      " Using Realtime:predictor:=[['0.00022043351782485843']]\n",
      " Using Realtime:predictor:=[['0.9996680021286011']]\n",
      "Done!\n"
     ]
    }
   ],
   "source": [
    "#import deprecations\n",
    "from sagemaker.predictor import (\n",
    "    json_serializer,\n",
    "    csv_serializer,\n",
    "    json_deserializer,\n",
    "    RealTimePredictor,\n",
    "    csv_deserializer,\n",
    ")\n",
    "from sagemaker.serializers import (\n",
    "    CSVSerializer,\n",
    "    JSONSerializer\n",
    ")\n",
    "from sagemaker.deserializers import (\n",
    "    CSVDeserializer\n",
    ")\n",
    "#from sagemaker.content_types import CONTENT_TYPE_CSV, CONTENT_TYPE_JSON\n",
    "\n",
    "print(\"content type csv\", \"text/csv\")\n",
    "end_point=\"arn:aws:sagemaker:us-east-1:034150676293:endpoint/smgithub2-staging\"\n",
    "end_point_name = \"smgithub2-staging\"\n",
    "\n",
    "#end_point=\"arn:aws:sagemaker:us-east-1:034150676293:endpoint/16-2022-04-25-22-45-01-389\"\n",
    "#end_point_name = \"16-2022-04-25-22-45-01-389\"\n",
    "\n",
    "realtime_predictor = RealTimePredictor(\n",
    "    endpoint_name=end_point_name,\n",
    "    sagemaker_session=sm_session,\n",
    "    serializer=CSVSerializer(), #csv_serializer,\n",
    "    deserializer=CSVDeserializer(), #csv_deserializer, # -- now it Returns a list \n",
    "    content_type=\"text/csv\",\n",
    "    accept=\"text/csv\",\n",
    ")\n",
    "\n",
    "#print(realtime_predictor.predict(payload))\n",
    "\n",
    "def invoke_smgithub_staging_endpoint(max_size=1, wait_interval_in_sec=1, should_raise_e=False, log_n_steps=1):\n",
    "    import pandas as pd\n",
    "    import time\n",
    "    end_point=\"arn:aws:sagemaker:us-east-1:034150676293:endpoint/smgithub2-staging\"\n",
    "    end_point_name = \"smgithub2-staging\"\n",
    "\n",
    "    #end_point=\"arn:aws:sagemaker:us-east-1:034150676293:endpoint/16-2022-04-25-22-45-01-389\"\n",
    "    #end_point_name = \"16-2022-04-25-22-45-01-389\"\n",
    "\n",
    "    sagemaker.s3.S3Downloader.download(s3_uri='s3://sagemaker-grewaltempl/data/finance/curated/small/test/test.csv', local_path='./tests/data', sagemaker_session=sm_session)\n",
    "    print(f\"Sending test traffic to the endpoint {end_point_name}. \\nPlease wait\", end=\"\")\n",
    "    test_dataset = \"./tests/data/test.csv\"\n",
    "    test_dataset_size = 0  # record the number of rows in data we're sending for inference\n",
    "    sagemaker_client = sm_session.sagemaker_client\n",
    "    sagemaker_runtime_client = sm_session.sagemaker_runtime_client\n",
    "    tweetsDF = pd.read_csv(test_dataset)\n",
    "\n",
    "    # -- FOR remove the 1st column as that is the Y_Labal \n",
    "    tweetsDF = tweetsDF.iloc[:,1:]\n",
    "    tweetsDF.to_csv(test_dataset, header=False, index=False, sep=\",\",na_rep=0 )\n",
    "    print(f\"::test:data:Minus_y_Label_column_::set:written:out:cols_length={tweetsDF.shape}::\")\n",
    "\n",
    "    with open(test_dataset, \"r\") as f:\n",
    "        for row in f:\n",
    "            if test_dataset_size < max_size:\n",
    "                #print(f\"::Going to invoke end point name={end_point_name}::test_dataset_size={test_dataset_size}::\")\n",
    "                payload = row.rstrip(\"\\n\")\n",
    "                response = sagemaker_runtime_client.invoke_endpoint(EndpointName=end_point_name,Body=payload,ContentType=\"text/csv\",)\n",
    "                prediction = response[\"Body\"].read()\n",
    "    #             print(\".\", end=\"\", flush=True)\n",
    "    #             print(f\"::GOT Prediction:={prediction}     :::response={response}:\")\n",
    "\n",
    "                # -- now try real time predictor\n",
    "                # - to reduce the logging log every N number of steps\n",
    "                if test_dataset_size % log_n_steps == 0:\n",
    "                    print(f\" Using Realtime:predictor:={realtime_predictor.predict(payload)}\")\n",
    "                time.sleep(wait_interval_in_sec)\n",
    "            test_dataset_size += 1\n",
    "\n",
    "print()\n",
    "invoke_smgithub_staging_endpoint(100, 1, False,1)\n",
    "print(\"Done!\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 319,
   "metadata": {},
   "outputs": [],
   "source": [
    "#!pip install xgboost==1.3.3"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Test using manually Extract the TAR balland then test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sagemaker.s3 import S3Downloader, S3Uploader\n",
    "import tarfile\n",
    "import xgboost as xgb\n",
    "import pandas as pd\n",
    "\n",
    "print(\"Evaluation:Starting evaluation.model_path\")\n",
    "model_path = os.path.join(BASE_DIR,  \"data\")\n",
    "s3_model_path = \"s3://sagemaker-grewaltempl/pipeline/model/xgbtrain/modeltweet/pipelines-qxt7e7b4fm4v-TrainTweetsStep-oMqXoidi0p/output/model.tar.gz\"     \n",
    "S3Downloader.download(s3_uri=s3_model_path, local_path=model_path)\n",
    "print(f\"Model:downloaded:to{model_path}::\")\n",
    "\n",
    "with tarfile.open(os.path.join(model_path,  \"model.tar.gz\")) as tar:\n",
    "    tar.extractall(path=os.path.join(BASE_DIR,  \"data\"))\n",
    "\n",
    "model = None\n",
    "\n",
    "if model == None:\n",
    "    try:\n",
    "        print(\"Evaluation:Loading xgboost model as JSON:: and :: BOOSTER :  \")\n",
    "        model = xgb.Booster()\n",
    "        model.load_model(os.path.join(BASE_DIR,  \"data/xgboost-model.json\"))\n",
    "    except:\n",
    "        import traceback\n",
    "        err_str = traceback.format_exc()\n",
    "        print(f\"Evaluation::error in loading BOOSTER:JSON:Booster:err_str={err_str}::\")\n",
    "            \n",
    "            \n",
    "print(f\"Evaluation:Model Loaded successfully:model={model}\")\n",
    "S3Downloader.download(s3_uri=\"s3://sagemaker-grewaltempl/data/finance/curated/small/test/test.csv\", local_path=os.path.join(BASE_DIR,  \"data\") )     \n",
    "test_path = os.path.join(BASE_DIR,  \"data/test.csv\")\n",
    "df_t = pd.read_csv(test_path, header=None)\n",
    "\n",
    "print(f\"Evaluation:Reading test data shape={df_t.shape}\")\n",
    "y_test = df_t.iloc[:, 0].to_numpy()\n",
    "X_test = df_t.iloc[:,1:].to_numpy() \n",
    "\n",
    "df_t_copy = df_t.drop(df_t.columns[0], axis=1)\n",
    "X_test_orig = xgb.DMatrix(df_t_copy.values)\n",
    "print(f\"Evaluate:trying:original:model:predictions:shape=rows={X_test_orig.num_row()}::cols={X_test_orig.num_col()}\")\n",
    "predictions = model.predict(X_test_orig) #X_val, label=y_val)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "predictions.size"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#model.predict(xgb.DMatrix(X_test))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Get the pipeline instance\n",
    "\n",
    "Here we get the pipeline instance from your pipeline module so that we can work with it."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# -=-= to force a reload of the module\n",
    "forceReLoadModule=True\n",
    "if forceReLoadModule:\n",
    "    import importlib\n",
    "    import pipelines.tweets.pipeline \n",
    "    importlib.reload(pipelines.tweets.pipeline)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pipelines.tweets.pipeline import get_pipeline\n",
    "\n",
    "\n",
    "pipeline_tw = get_pipeline(\n",
    "    region=region,\n",
    "    role=role,\n",
    "    default_bucket=default_bucket,\n",
    "    model_package_group_name=model_package_group_name,\n",
    "    pipeline_name=pipeline_name,\n",
    ")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pipeline.upsert(role_arn=role)\n",
    "execution = pipeline_tw.start(\n",
    "    parameters=dict(\n",
    "        ProcessingInstanceType=\"ml.c5.xlarge\",\n",
    "        ModelApprovalStatus=\"Rejected\",\n",
    "    )\n",
    ")\n",
    "execution.wait()\n",
    "execution.list_steps()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "###  Now write out the FULL Pipeline.py file"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%writefile ./pipelines/tweets/pipeline.py\n",
    "\n",
    "import os\n",
    "\n",
    "import boto3\n",
    "import sagemaker\n",
    "import sagemaker.session\n",
    "\n",
    "from sagemaker.estimator import Estimator\n",
    "from sagemaker.inputs import TrainingInput\n",
    "from sagemaker.model_metrics import (\n",
    "    MetricsSource,\n",
    "    ModelMetrics,\n",
    ")\n",
    "from sagemaker.processing import (\n",
    "    ProcessingInput,\n",
    "    ProcessingOutput,\n",
    "    ScriptProcessor,\n",
    "    FrameworkProcessor\n",
    ")\n",
    "from sagemaker.sklearn.processing import SKLearnProcessor\n",
    "from sagemaker.workflow.conditions import ConditionLessThanOrEqualTo\n",
    "from sagemaker.workflow.condition_step import (\n",
    "    ConditionStep,\n",
    "    JsonGet,\n",
    ")\n",
    "from sagemaker.workflow.parameters import (\n",
    "    ParameterInteger,\n",
    "    ParameterString,\n",
    ")\n",
    "from sagemaker.workflow.pipeline import Pipeline\n",
    "from sagemaker.workflow.properties import PropertyFile\n",
    "from sagemaker.workflow.steps import (\n",
    "    ProcessingStep,\n",
    "    TrainingStep,\n",
    ")\n",
    "from sagemaker.workflow.step_collections import RegisterModel\n",
    "\n",
    "from sagemaker.workflow.conditions import (\n",
    "    ConditionGreaterThanOrEqualTo,\n",
    ")\n",
    "\n",
    "from sagemaker.sklearn import SKLearnModel\n",
    "from sagemaker.xgboost import XGBoostModel\n",
    "from sagemaker.model import Model\n",
    "\n",
    "from sagemaker.workflow.steps import CreateModelStep\n",
    "\n",
    "\n",
    "BASE_DIR = os.path.dirname(os.path.realpath(__file__))\n",
    "\n",
    "def get_sagemaker_client(region):\n",
    "    \"\"\"Gets the sagemaker client.\n",
    "\n",
    "        Args:\n",
    "            region: the aws region to start the session\n",
    "            default_bucket: the bucket to use for storing the artifacts\n",
    "\n",
    "        Returns:\n",
    "            `sagemaker.session.Session instance\n",
    "    \"\"\"\n",
    "    boto_session = boto3.Session(region_name=region)\n",
    "    sagemaker_client = boto_session.client(\"sagemaker\")\n",
    "    return sagemaker_client\n",
    "\n",
    "\n",
    "def get_session(region, default_bucket):\n",
    "    \"\"\"Gets the sagemaker session based on the region.\n",
    "\n",
    "    Args:\n",
    "        region: the aws region to start the session\n",
    "        default_bucket: the bucket to use for storing the artifacts\n",
    "\n",
    "    Returns:\n",
    "        `sagemaker.session.Session instance\n",
    "    \"\"\"\n",
    "\n",
    "    boto_session = boto3.Session(region_name=region)\n",
    "\n",
    "    sagemaker_client = boto_session.client(\"sagemaker\")\n",
    "    runtime_client = boto_session.client(\"sagemaker-runtime\")\n",
    "    return sagemaker.session.Session(\n",
    "        boto_session=boto_session,\n",
    "        sagemaker_client=sagemaker_client,\n",
    "        sagemaker_runtime_client=runtime_client,\n",
    "        default_bucket=default_bucket,\n",
    "    )\n",
    "\n",
    "def get_pipeline_custom_tags(new_tags, region, sagemaker_project_arn=None):\n",
    "    try:\n",
    "        sm_client = get_sagemaker_client(region)\n",
    "        response = sm_client.list_tags(\n",
    "            ResourceArn=sagemaker_project_arn)\n",
    "        project_tags = response[\"Tags\"]\n",
    "        for project_tag in project_tags:\n",
    "            new_tags.append(project_tag)\n",
    "    except Exception as e:\n",
    "        print(f\"Error getting project tags: {e}\")\n",
    "    return new_tags\n",
    "\n",
    "\n",
    "def get_pipeline(\n",
    "    region,\n",
    "    sagemaker_project_arn=None,\n",
    "    role=None,\n",
    "    default_bucket=None,\n",
    "    model_package_group_name=\"TweetsPackageGroup\",\n",
    "    pipeline_name=\"TweetsPipeline\",\n",
    "    base_job_prefix=\"Tweets\",\n",
    "):\n",
    "    \"\"\"Gets a SageMaker ML Pipeline instance working with on abalone data.\n",
    "\n",
    "    Args:\n",
    "        region: AWS region to create and run the pipeline.\n",
    "        role: IAM role to create and run steps and pipeline.\n",
    "        default_bucket: the bucket to use for storing the artifacts\n",
    "\n",
    "    Returns:\n",
    "        an instance of a pipeline\n",
    "    \"\"\"\n",
    "    sm_session = get_session(region, default_bucket)\n",
    "    if role is None:\n",
    "        role = sagemaker.session.get_execution_role(sm_session)\n",
    "        \n",
    "    #default_bucket = sm_session.default_bucket()\n",
    "\n",
    "    print(f\"Using:role={role}:\")\n",
    "    print(f\"using SageMaker session={sm_session}:\")\n",
    "\n",
    "    # Parameters for pipeline execution\n",
    "    processing_instance_count = ParameterInteger(\n",
    "            name=\"ProcessingInstanceCount\", default_value=1\n",
    "    )\n",
    "    processing_instance_type = ParameterString(\n",
    "            name=\"ProcessingInstanceType\", default_value=\"ml.m5.xlarge\"\n",
    "    )\n",
    "    training_instance_type = ParameterString(\n",
    "            name=\"TrainingInstanceType\", default_value=\"ml.m5.xlarge\"\n",
    "    )\n",
    "    model_approval_status = ParameterString(\n",
    "            name=\"ModelApprovalStatus\",\n",
    "            default_value=\"PendingManualApproval\",  # ModelApprovalStatus can be set to a default of \"Approved\" if you don't want manual approval.\n",
    "    )\n",
    "    input_data = ParameterString(\n",
    "            name=\"InputDataUrl\",\n",
    "            default_value=f\"s3://{default_bucket}/data/finance/combined_tweets.csvv\",  # Change this to point to the s3 location of your raw input data.\n",
    "    )\n",
    "    print(f\"pipeline:get_pipeline::processor:\")\n",
    "    # Cache Pipeline steps to reduce execution time on subsequent executions\n",
    "\n",
    "    from sagemaker.workflow.steps import CacheConfig\n",
    "    cache_config = CacheConfig(enable_caching=True, expire_after=\"1d\")\n",
    "    print(f\"pipeline::get_pipeline:cache:config:enabled:\")\n",
    "\n",
    "    print(f\"Pipeline_name={pipeline_name}:\")\n",
    "    print(f\"Pipeline:base:job:prefix={base_job_prefix}:\")\n",
    "\n",
    "\n",
    "\n",
    "    # Processing step for feature engineering\n",
    "    sklearn_processor = SKLearnProcessor(\n",
    "            framework_version=\"0.23-1\",\n",
    "            instance_type=processing_instance_type,\n",
    "            instance_count=processing_instance_count,\n",
    "            base_job_name=f\"smjobs-sklearn-tweets-preprocess/{base_job_prefix}\" ,#f\"{BASE_JOB_PREFIX}-sklearn-TweetsChurn-preprocess\",  # choose any name\n",
    "            sagemaker_session=sm_session,\n",
    "            role=role,\n",
    "        )\n",
    "\n",
    "    inputs_p=[\n",
    "        ProcessingInput(\n",
    "            source=f\"s3://{default_bucket}/data/finance/combined_tweets.csv\",\n",
    "            destination='/opt/ml/processing/input'\n",
    "        ),\n",
    "     ]\n",
    "    outputs_p=[\n",
    "        ProcessingOutput(\n",
    "            s3_upload_mode=\"EndOfJob\",\n",
    "            output_name='train',\n",
    "            source='/opt/ml/processing/train',\n",
    "            destination=f's3://{default_bucket}/data/finance/curated/small/train'\n",
    "        ),\n",
    "        ProcessingOutput(\n",
    "            s3_upload_mode=\"EndOfJob\",\n",
    "            output_name='test',\n",
    "            source='/opt/ml/processing/test',\n",
    "            destination=f's3://{default_bucket}/data/finance/curated/small/test'\n",
    "        ),\n",
    "        ProcessingOutput(\n",
    "            s3_upload_mode=\"EndOfJob\",\n",
    "            output_name='validation',\n",
    "            source='/opt/ml/processing/val',\n",
    "            destination=f's3://{default_bucket}/data/finance/curated/small/validation'\n",
    "        ),\n",
    "        ProcessingOutput(\n",
    "            output_name=\"evaluation-property-pass\",\n",
    "            source=\"/opt/ml/processing/evalproperty\",\n",
    "            destination=f's3://{default_bucket}/data/finance/curated/small/evalproperty'\n",
    "        ),\n",
    "\n",
    "\n",
    "    ]\n",
    "    # -- if we d onot create a output then this directory is never creatd on tbe processing job\n",
    "    evaluation_report_preproc = PropertyFile(\n",
    "        name=\"EvaluationReportPreproc\",\n",
    "        output_name=\"evaluation-property-pass\", # -- matches the processing output name\n",
    "        path=\"evaluation.json\",\n",
    "    )\n",
    "\n",
    "    job_arguments_p=[\"--input-data\", f\"s3://{default_bucket}/data/finance/combined_tweets.csv\", \n",
    "                  \"--data-size\", \"10000\"]\n",
    "    step_process = ProcessingStep(\n",
    "            name=\"PreProcTweetsModelPipe\",  # choose any name\n",
    "            processor=sklearn_processor,\n",
    "            inputs=inputs_p,\n",
    "            outputs=outputs_p,\n",
    "            property_files=[evaluation_report_preproc],\n",
    "            code=os.path.join(BASE_DIR, \"preprocess_tweets.py\"),\n",
    "            job_arguments=job_arguments_p,\n",
    "            cache_config=cache_config\n",
    "        )    \n",
    "\n",
    "    print(f\"SageMaker:pipeline:get_pipeline::Preproc:step:added={step_process}\")\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "    import boto3\n",
    "    from sagemaker.xgboost.estimator import XGBoost\n",
    "    from sagemaker import TrainingInput\n",
    "\n",
    "    # -- CANNOT USE this for Sagemaker Algorithims \n",
    "    metrics_definetion = [\n",
    "            {'Name': 'train:loss', 'Regex': 'loss: ([0-9\\\\.]+)'},\n",
    "            {'Name': 'train.accuracy', 'Regex': 'accuracy: ([0-9\\\\.]+)'},\n",
    "            {'Name': 'validation.loss', 'Regex': 'val_loss: ([0-9\\\\.]+)'},\n",
    "            {'Name': 'validation.accuracy', 'Regex': 'val_accuracy: ([0-9\\\\.]+)'},\n",
    "    ]\n",
    "    xgb_hyperparams = dict (\n",
    "            objective=\"reg:linear\",\n",
    "            num_round=50,\n",
    "            max_depth=5,\n",
    "            eta=0.2,\n",
    "            gamma=4,\n",
    "            min_child_weight=6,\n",
    "            subsample=0.7,\n",
    "            silent=0,\n",
    "        )\n",
    "\n",
    "    use_spot_instances = True\n",
    "    max_run = 3600\n",
    "    max_wait = 7200 if use_spot_instances else None\n",
    "\n",
    "    xgb_custom_estimator = XGBoost(\n",
    "        role=role, \n",
    "        entry_point=os.path.join(BASE_DIR, 'modeltrain.py'),\n",
    "        framework_version=\"1.3-1\",\n",
    "        instance_count=1,\n",
    "        instance_type='ml.m5.large', # - 'local', only if docker is installed locally \n",
    "        output_path=f's3://{default_bucket}/pipeline/model/xgbtrain/modeltweet',\n",
    "        use_spot_instances=use_spot_instances,\n",
    "        max_run=max_run,\n",
    "        max_wait=max_wait,\n",
    "        hyperparameters=xgb_hyperparams,\n",
    "        base_job_name=f\"TrainTweetsModelPipe/{base_job_prefix}\",\n",
    "        code_location=f\"s3://{default_bucket}/pipeline/model/xgbtrain/code\", \n",
    "        #source_dir=\"scripts\", # This line will tell SageMaker to first install defined dependencies from scrits/requirements.txt,\n",
    "        # -- and then to upload all code inside of this folder to your container.\n",
    "        #metric_definitions=metrics_definetion, # -- using XgBoost cannot override default SageMaker metrics\n",
    "\n",
    "    )\n",
    "\n",
    "    step_train = TrainingStep(\n",
    "        name=\"TrainTweetsStep\",\n",
    "        estimator=xgb_custom_estimator,\n",
    "        inputs={\n",
    "            \"train\": TrainingInput( # -- name need to match output name of pre proc\n",
    "                    s3_data=step_process.properties.ProcessingOutputConfig.Outputs[\n",
    "                        \"train\" \n",
    "                    ].S3Output.S3Uri,\n",
    "                    content_type=\"text/csv\",\n",
    "            ),\n",
    "            \"validation\": TrainingInput(\n",
    "                    s3_data=step_process.properties.ProcessingOutputConfig.Outputs[\n",
    "                        \"validation\"\n",
    "                    ].S3Output.S3Uri,\n",
    "                    content_type=\"text/csv\",\n",
    "            ),\n",
    "        },\n",
    "        cache_config=cache_config\n",
    "    )\n",
    "\n",
    "    print(f\"SageMaker:pipeline:get_pipeline::TRAINING:step:added={step_train}\")\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "    # processing step for evaluation\n",
    "    # -- FrameworkProcessor and XgBoostProcessor work best since we can do requirememts.txt in source_dir\n",
    "    # -- SKLearnProcessor will not work since we need additonal libraries\n",
    "\n",
    "    image_uri = sagemaker.image_uris.retrieve(\n",
    "            framework=\"xgboost\",  # we are using the Sagemaker built in xgboost algorithm\n",
    "            region=region,\n",
    "            version=\"1.3-1\", #\"1.0-1\",\n",
    "            py_version=\"py3\",\n",
    "            instance_type=training_instance_type,\n",
    "    )\n",
    "\n",
    "    est_cls = sagemaker.xgboost.estimator.XGBoost\n",
    "    framework_version_str=\"1.3-1\"\n",
    "    framework_processor_eval = FrameworkProcessor( #  ScriptProcessor( #  FrameworkProcessor\n",
    "            estimator_cls=est_cls,\n",
    "            image_uri=image_uri,\n",
    "            framework_version=framework_version_str,\n",
    "            command=[\"python3\"],\n",
    "            instance_type=processing_instance_type,\n",
    "            instance_count=1,\n",
    "            base_job_name=f\"script-tweets-eval/{base_job_prefix}\",\n",
    "            sagemaker_session=sm_session,\n",
    "            role=role, \n",
    "    )\n",
    "    run_args = framework_processor_eval.get_run_args(\n",
    "        code=\"evaluate.py\",#os.path.join(BASE_DIR,  \"scripts_eval/evaluate.py\"),\n",
    "        source_dir=os.path.join(BASE_DIR,  \"scripts_eval\"),\n",
    "        inputs=[\n",
    "                ProcessingInput(\n",
    "                    source=step_train.properties.ModelArtifacts.S3ModelArtifacts,\n",
    "                    destination=\"/opt/ml/processing/model\",\n",
    "                ),\n",
    "                ProcessingInput(\n",
    "                    source=step_process.properties.ProcessingOutputConfig.Outputs[\n",
    "                        \"test\"\n",
    "                    ].S3Output.S3Uri,\n",
    "                    destination=\"/opt/ml/processing/test\",\n",
    "                ),\n",
    "        ],\n",
    "        outputs=[\n",
    "                ProcessingOutput(output_name=\"evaluation\", source=\"/opt/ml/processing/evaluation\"),\n",
    "        ],\n",
    "        arguments=None\n",
    "    )\n",
    "    evaluation_report = PropertyFile(\n",
    "            name=\"TweetsEvaluationReport\",\n",
    "            output_name=\"evaluation\",\n",
    "            path=\"evaluation.json\",\n",
    "    )\n",
    "    step_eval = ProcessingStep(\n",
    "            name=\"EvaluateTweetsModelPipe\",\n",
    "            processor=framework_processor_eval,\n",
    "            inputs=run_args.inputs,\n",
    "            outputs=run_args.outputs,\n",
    "            code=run_args.code,\n",
    "            property_files=[evaluation_report],\n",
    "\n",
    "    )\n",
    "    print(f\"SageMaker:pipeline:get_pipeline::EVALUATION:step:added={step_eval}\")\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "    # register model step that will be conditionally executed\n",
    "    model_metrics = ModelMetrics(\n",
    "            model_statistics=MetricsSource(\n",
    "                s3_uri=\"{}/evaluation.json\".format(\n",
    "                    step_eval.arguments[\"ProcessingOutputConfig\"][\"Outputs\"][0][\"S3Output\"][\"S3Uri\"]\n",
    "                ),\n",
    "                content_type=\"application/json\"\n",
    "            )\n",
    "    )\n",
    "    model_tags = [\n",
    "        {'Key': 'sagemaker:deployment-stage', 'Value': 'prod'},\n",
    "        {'Key': 'sagemaker:short-description', 'Value': 'test-describe'},\n",
    "        {'Key': 'sagemaker:project-name', 'Value': 'test-name'},\n",
    "    ]\n",
    "    ##  -----  TESTING Create Model froma pre ptrained and use that to host ---- ###\n",
    "    # -- THIS MODEL has been trained in SM but different package and all  \n",
    "    pretrained_s3=\"s3://sagemaker-grewaltempl/pipeline/model/xgbtrain/modeltweet/pipelines-vqlln8kv20ti-TrainTweetsStep-EG5BCPA1eB/output/model.tar.gz\"\n",
    "    xgboost_model = XGBoostModel(\n",
    "        #model_data=step_train.properties.ModelArtifacts.S3ModelArtifacts,\n",
    "        model_data=pretrained_s3, \n",
    "        entry_point='inference.py',\n",
    "        source_dir=os.path.join(BASE_DIR,  'xgboost_source_dir'),\n",
    "        #code_location=f\"s3://{sagemaker_session.default_bucket()}/imlabs/pipeline/model/pipe_tweets/{base_job_prefix}\",\n",
    "        framework_version='1.3-1',\n",
    "        py_version='py3',\n",
    "        sagemaker_session=sm_session,\n",
    "        role=role\n",
    "    )\n",
    "    step_create_xgboost_model = CreateModelStep(\n",
    "        name=\"XGBoostFromSavedModel\",\n",
    "        model=xgboost_model,\n",
    "        inputs=sagemaker.inputs.CreateModelInput(instance_type=\"ml.m4.large\"),\n",
    "    )    \n",
    "\n",
    "    ##  ------  END TESTING PRE TRAINED MODEL ----------------------------------##\n",
    "    \n",
    "    step_register = RegisterModel(\n",
    "            name=\"RegisterTweetsModel\",\n",
    "            estimator=xgb_custom_estimator,\n",
    "            model_data=step_train.properties.ModelArtifacts.S3ModelArtifacts,\n",
    "            #model=xgboost_model,\n",
    "            content_types=[\"text/csv\"],\n",
    "            response_types=[\"text/csv\"],\n",
    "            inference_instances=[\"ml.t2.medium\", \"ml.m5.large\"],\n",
    "            transform_instances=[\"ml.m5.large\"],\n",
    "            model_package_group_name=model_package_group_name,\n",
    "            approval_status=model_approval_status,\n",
    "            model_metrics=model_metrics,\n",
    "            tags=model_tags,\n",
    "            description=\"Test-Description\",\n",
    "    )\n",
    "\n",
    "\n",
    "    cond_lte_register = ConditionGreaterThanOrEqualTo(  # You can change the condition here\n",
    "            left=JsonGet(\n",
    "                step=step_eval,\n",
    "                #step_name=step_eval.name,#\"EvaluateTweetsModel\", # has to match the step evaluation name # old --step=step_process\n",
    "                property_file=evaluation_report,\n",
    "                json_path=\"regression_metrics.mse.value\",  # This should follow the structure of your report_dict defined in the \n",
    "            ),\n",
    "            right=0.01,  # You can change the threshold here\n",
    "    )\n",
    "    step_cond_register = ConditionStep(\n",
    "            name=\"TweetsRegisterAccuracyCond\",\n",
    "            conditions=[cond_lte_register],\n",
    "            if_steps=[step_register],\n",
    "            else_steps=[],\n",
    "    )\n",
    "    print(f\"Sagemaker:pipelines: Finally register:condition:step:created={step_cond_register}:\")\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "    # pipeline instance\n",
    "    pipeline = Pipeline(\n",
    "            name=pipeline_name,\n",
    "            parameters=[\n",
    "                processing_instance_type,\n",
    "                processing_instance_count,\n",
    "                training_instance_type,\n",
    "                model_approval_status,\n",
    "                input_data,\n",
    "            ],\n",
    "            steps=[step_process, step_train, step_eval, step_cond_register ],\n",
    "            sagemaker_session=sm_session,\n",
    "    )\n",
    "    print(f\"Finally Pipeline created={pipeline}:\")\n",
    "\n",
    "\n",
    "    return pipeline\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Now we test the end point"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 321,
   "metadata": {},
   "outputs": [],
   "source": [
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "warnings.simplefilter('ignore')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 422,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "The class RealTimePredictor has been renamed in sagemaker>=2.\n",
      "See: https://sagemaker.readthedocs.io/en/stable/v2.html for details.\n",
      "content_type is a no-op in sagemaker>=2.\n",
      "See: https://sagemaker.readthedocs.io/en/stable/v2.html for details.\n",
      "accept is a no-op in sagemaker>=2.\n",
      "See: https://sagemaker.readthedocs.io/en/stable/v2.html for details.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "content type csv text/csv\n",
      "\n",
      "Sending test traffic to the endpoint smgithub2-staging. \n",
      "Please wait::test:data:Minus_y_Label_column_::set:written:out:cols_length=(999, 9)::\n",
      " Using Realtime:predictor:=[['0.00022043351782485843']]\n",
      " Using Realtime:predictor:=[['0.00022043351782485843']]\n",
      "Done!\n"
     ]
    }
   ],
   "source": [
    "#import deprecations\n",
    "from sagemaker.predictor import (\n",
    "    json_serializer,\n",
    "    csv_serializer,\n",
    "    json_deserializer,\n",
    "    RealTimePredictor,\n",
    "    csv_deserializer,\n",
    ")\n",
    "from sagemaker.serializers import (\n",
    "    CSVSerializer,\n",
    "    JSONSerializer\n",
    ")\n",
    "from sagemaker.deserializers import (\n",
    "    CSVDeserializer\n",
    ")\n",
    "#from sagemaker.content_types import CONTENT_TYPE_CSV, CONTENT_TYPE_JSON\n",
    "\n",
    "payload = \"rental,peanut,butter\"\n",
    "print(\"content type csv\", \"text/csv\")\n",
    "end_point=\"arn:aws:sagemaker:us-east-1:034150676293:endpoint/smgithub2-staging\"\n",
    "end_point_name = \"smgithub2-staging\"\n",
    "realtime_predictor = RealTimePredictor(\n",
    "    endpoint_name=end_point_name,\n",
    "    sagemaker_session=sm_session,\n",
    "    serializer=CSVSerializer(), #csv_serializer,\n",
    "    deserializer=CSVDeserializer(), #csv_deserializer, # -- now it Returns a list \n",
    "    content_type=\"text/csv\",\n",
    "    accept=\"text/csv\",\n",
    ")\n",
    "\n",
    "#print(realtime_predictor.predict(payload))\n",
    "\n",
    "def invoke_smgithub_staging_endpoint(max_size=1, wait_interval_in_sec=1, should_raise_e=False, log_n_steps=1):\n",
    "    import pandas as pd\n",
    "    import time\n",
    "    end_point=\"arn:aws:sagemaker:us-east-1:034150676293:endpoint/smgithub2-staging\"\n",
    "    end_point_name = \"smgithub2-staging\"\n",
    "\n",
    "    sagemaker.s3.S3Downloader.download(s3_uri='s3://sagemaker-grewaltempl/data/finance/curated/small/test/test.csv', local_path='./tests/data', sagemaker_session=sm_session)\n",
    "    print(f\"Sending test traffic to the endpoint {end_point_name}. \\nPlease wait\", end=\"\")\n",
    "    test_dataset = \"./tests/data/test.csv\"\n",
    "    test_dataset_size = 0  # record the number of rows in data we're sending for inference\n",
    "    sagemaker_client = sm_session.sagemaker_client\n",
    "    sagemaker_runtime_client = sm_session.sagemaker_runtime_client\n",
    "    tweetsDF = pd.read_csv(test_dataset)\n",
    "\n",
    "    # -- FOR remove the 1st column as that is the Y_Labal \n",
    "    tweetsDF = tweetsDF.iloc[:,1:]\n",
    "    tweetsDF.to_csv(test_dataset, header=False, index=False, sep=\",\",na_rep=0 )\n",
    "    print(f\"::test:data:Minus_y_Label_column_::set:written:out:cols_length={tweetsDF.shape}::\")\n",
    "\n",
    "    with open(test_dataset, \"r\") as f:\n",
    "        for row in f:\n",
    "            if test_dataset_size < max_size:\n",
    "                #print(f\"::Going to invoke end point name={end_point_name}::test_dataset_size={test_dataset_size}::\")\n",
    "                payload = row.rstrip(\"\\n\")\n",
    "                response = sagemaker_runtime_client.invoke_endpoint(EndpointName=end_point_name,Body=payload,ContentType=\"text/csv\",)\n",
    "                prediction = response[\"Body\"].read()\n",
    "    #             print(\".\", end=\"\", flush=True)\n",
    "    #             print(f\"::GOT Prediction:={prediction}     :::response={response}:\")\n",
    "\n",
    "                # -- now try real time predictor\n",
    "                # - to reduce the logging log every N number of steps\n",
    "                if test_dataset_size % log_n_steps == 0:\n",
    "                    print(f\" Using Realtime:predictor:={realtime_predictor.predict(payload)}\")\n",
    "                time.sleep(wait_interval_in_sec)\n",
    "            test_dataset_size += 1\n",
    "\n",
    "print()\n",
    "invoke_smgithub_staging_endpoint(100, 1, False,50)\n",
    "print(\"Done!\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 540,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "%matplotlib inline\n",
    "import pandas as pd\n",
    "import time\n",
    "import re\n",
    "import json\n",
    "import botocore\n",
    "import boto3\n",
    "from datetime import datetime, timedelta, timezone\n",
    "\n",
    "cw = boto3.Session().client(\"cloudwatch\", region_name=region)\n",
    "variant_name='AllTraffic'\n",
    "endpoint_config_name = 'EndpointConfig-HQTcEUTAXjLV'\n",
    "end_point=\"arn:aws:sagemaker:us-east-1:034150676293:endpoint/smgithub2-staging\"\n",
    "endpoint_name = \"smgithub2-staging\"\n",
    "\n",
    "def get_sagemaker_metrics(\n",
    "    endpoint_name,\n",
    "    endpoint_config_name,\n",
    "    variant_name,\n",
    "    metric_name,\n",
    "    statistic,\n",
    "    start_time,\n",
    "    end_time,\n",
    "):\n",
    "    dimensions = [\n",
    "        {\"Name\": \"EndpointName\", \"Value\": endpoint_name},\n",
    "        {\"Name\": \"VariantName\", \"Value\": variant_name},\n",
    "    ]\n",
    "    if endpoint_config_name is not None:\n",
    "        dimensions.append({\"Name\": \"EndpointConfigName\", \"Value\": endpoint_config_name})\n",
    "    metrics = cw.get_metric_statistics(\n",
    "        Namespace=\"AWS/SageMaker\",\n",
    "        MetricName=metric_name,\n",
    "        StartTime=start_time,\n",
    "        EndTime=end_time,\n",
    "        Period=60,\n",
    "        Statistics=[statistic],\n",
    "        Dimensions=dimensions,\n",
    "    )\n",
    "    rename = endpoint_config_name if endpoint_config_name is not None else \"ALL\"\n",
    "    if len(metrics[\"Datapoints\"]) == 0:\n",
    "        return\n",
    "    return (\n",
    "        pd.DataFrame(metrics[\"Datapoints\"])\n",
    "        .sort_values(\"Timestamp\")\n",
    "        .set_index(\"Timestamp\")\n",
    "        .drop([\"Unit\"], axis=1)\n",
    "        .rename(columns={statistic: rename})\n",
    "    )\n",
    "\n",
    "\n",
    "def plot_endpoint_invocation_metrics(\n",
    "    endpoint_name,\n",
    "    endpoint_config_name,\n",
    "    variant_name,\n",
    "    metric_name,\n",
    "    statistic,\n",
    "    start_time=None,\n",
    "):\n",
    "    start_time = start_time or datetime.now(timezone.utc) - timedelta(minutes=60)\n",
    "    end_time = datetime.now(timezone.utc)\n",
    "    metrics_variants = get_sagemaker_metrics(\n",
    "        endpoint_name,\n",
    "        endpoint_config_name,\n",
    "        variant_name,\n",
    "        metric_name,\n",
    "        statistic,\n",
    "        start_time,\n",
    "        end_time,\n",
    "    )\n",
    "    if metrics_variants is None:\n",
    "        return\n",
    "    metrics_variants.plot(title=f\"{metric_name}-{statistic}\")\n",
    "    return metrics_variants"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 543,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Created CUSTOM Endpoint Config: {'EndpointConfigArn': 'arn:aws:sagemaker:us-east-1:034150676293:endpoint-config/endpointconfig-smgithub2-staging-xg-custom', 'ResponseMetadata': {'RequestId': 'e9f2c090-1fec-4957-90dc-02bab8043073', 'HTTPStatusCode': 200, 'HTTPHeaders': {'x-amzn-requestid': 'e9f2c090-1fec-4957-90dc-02bab8043073', 'content-type': 'application/x-amz-json-1.1', 'content-length': '123', 'date': 'Mon, 18 Apr 2022 02:27:42 GMT'}, 'RetryAttempts': 0}}\n"
     ]
    }
   ],
   "source": [
    "if 1 == 2:\n",
    "    model_name_46_new=\"Model-8k4sUQv2be9L\"\n",
    "    model_name_xgboost=\"pipelines-ry6dcya6wtu3-XGBoostFromSavedMode-X6bd89Ss1B\"\n",
    "    # - 'arn:aws:sagemaker:us-east-1:034150676293:endpoint-config/endpointconfig-smgithub2-staging-xg-custom\n",
    "    resp = sm_client.create_endpoint_config(   # -- CREAYED -- ''\n",
    "        EndpointConfigName=\"EndpointConfig-smgithub2-staging-XG-CUSTOM\",\n",
    "        ProductionVariants=[\n",
    "            {\n",
    "                \"VariantName\": \"AllTraffic\",\n",
    "                \"ModelName\": model_name_xgboost,\n",
    "                \"InstanceType\": \"ml.m5.large\",\n",
    "                \"InitialInstanceCount\": 2,\n",
    "            }\n",
    "        ],\n",
    "    )\n",
    "    print(f\"Created CUSTOM Endpoint Config: {resp}\")\n",
    "    time.sleep(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 544,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "variant_name='AllTraffic'\n",
    "ep_config_name = 'EndpointConfig-HQTcEUTAXjLV'\n",
    "end_point=\"arn:aws:sagemaker:us-east-1:034150676293:endpoint/smgithub2-staging\"\n",
    "endpoint_name = \"smgithub2-staging\"\n",
    "ep_config_2nd_name = \"EndpointConfig-smgithub2-staging-XG-CUSTOM\"\n",
    "\n",
    "invocation_metrics = plot_endpoint_invocation_metrics(\n",
    "    endpoint_name, ep_config_name, \"AllTraffic\", \"Invocations\", \"Sum\"\n",
    ")\n",
    "invocation_4xx_metrics = plot_endpoint_invocation_metrics(\n",
    "    endpoint_name, None, \"AllTraffic\", \"Invocation4XXErrors\", \"Sum\"\n",
    ")\n",
    "invocation_5xx_metrics = plot_endpoint_invocation_metrics(\n",
    "    endpoint_name, None, \"AllTraffic\", \"Invocation5XXErrors\", \"Sum\"\n",
    ")\n",
    "model_latency_metrics = plot_endpoint_invocation_metrics(\n",
    "    endpoint_name, None, \"AllTraffic\", \"ModelLatency\", \"Average\"\n",
    ")\n",
    "overhead_latency_metrics = plot_endpoint_invocation_metrics(\n",
    "    endpoint_name, None, \"AllTraffic\", \"OverheadLatency\", \"Average\"\n",
    ")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Now is the Cloud watch Alarm --"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 325,
   "metadata": {},
   "outputs": [],
   "source": [
    "cw = boto3.Session().client(\"cloudwatch\", region_name=region)\n",
    "variant_name='AllTraffic'\n",
    "ep_config_name = 'EndpointConfig-HQTcEUTAXjLV'\n",
    "end_point=\"arn:aws:sagemaker:us-east-1:034150676293:endpoint/smgithub2-staging\"\n",
    "endpoint_name = \"smgithub2-staging\"\n",
    "endpoint_2nd_name = \"smgithub2-staging-CUSTOM\"\n",
    "\n",
    "def create_auto_rollback_alarm(\n",
    "    alarm_name, endpoint_name, variant_name, metric_name, statistic, threshold\n",
    "):\n",
    "    cw.put_metric_alarm(\n",
    "        AlarmName=alarm_name,\n",
    "        AlarmDescription=\"Test SageMaker endpoint deployment auto-rollback alarm\",\n",
    "        ActionsEnabled=False,\n",
    "        Namespace=\"AWS/SageMaker\",\n",
    "        MetricName=metric_name,\n",
    "        Statistic=statistic,\n",
    "        Dimensions=[\n",
    "            {\"Name\": \"EndpointName\", \"Value\": endpoint_name},\n",
    "            {\"Name\": \"VariantName\", \"Value\": variant_name},\n",
    "        ],\n",
    "        Period=60,\n",
    "        EvaluationPeriods=1,\n",
    "        Threshold=threshold,\n",
    "        ComparisonOperator=\"GreaterThanOrEqualToThreshold\",\n",
    "        TreatMissingData=\"notBreaching\",\n",
    "    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 326,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'CompositeAlarms': [],\n",
       " 'MetricAlarms': [{'AlarmName': 'TestSMGitHub2Alarm-5XXErrors-smgithub2-staging',\n",
       "   'AlarmArn': 'arn:aws:cloudwatch:us-east-1:034150676293:alarm:TestSMGitHub2Alarm-5XXErrors-smgithub2-staging',\n",
       "   'AlarmDescription': 'Test SageMaker endpoint deployment auto-rollback alarm',\n",
       "   'AlarmConfigurationUpdatedTimestamp': datetime.datetime(2022, 4, 14, 15, 4, 5, 963000, tzinfo=tzlocal()),\n",
       "   'ActionsEnabled': False,\n",
       "   'OKActions': [],\n",
       "   'AlarmActions': [],\n",
       "   'InsufficientDataActions': [],\n",
       "   'StateValue': 'OK',\n",
       "   'StateReason': 'Threshold Crossed: no datapoints were received for 1 period and 1 missing datapoint was treated as [NonBreaching].',\n",
       "   'StateReasonData': '{\"version\":\"1.0\",\"queryDate\":\"2022-04-14T15:04:27.064+0000\",\"statistic\":\"Average\",\"period\":60,\"recentDatapoints\":[],\"threshold\":1.0,\"evaluatedDatapoints\":[{\"timestamp\":\"2022-04-14T15:04:00.000+0000\"}]}',\n",
       "   'StateUpdatedTimestamp': datetime.datetime(2022, 4, 14, 15, 4, 27, 168000, tzinfo=tzlocal()),\n",
       "   'MetricName': 'Invocation5XXErrors',\n",
       "   'Namespace': 'AWS/SageMaker',\n",
       "   'Statistic': 'Average',\n",
       "   'Dimensions': [{'Name': 'EndpointName', 'Value': 'smgithub2-staging'},\n",
       "    {'Name': 'VariantName', 'Value': 'AllTraffic'}],\n",
       "   'Period': 60,\n",
       "   'EvaluationPeriods': 1,\n",
       "   'Threshold': 1.0,\n",
       "   'ComparisonOperator': 'GreaterThanOrEqualToThreshold',\n",
       "   'TreatMissingData': 'notBreaching'},\n",
       "  {'AlarmName': 'TestSMGitHub2Alarm-ModelLatency-smgithub2-staging',\n",
       "   'AlarmArn': 'arn:aws:cloudwatch:us-east-1:034150676293:alarm:TestSMGitHub2Alarm-ModelLatency-smgithub2-staging',\n",
       "   'AlarmDescription': 'Test SageMaker endpoint deployment auto-rollback alarm',\n",
       "   'AlarmConfigurationUpdatedTimestamp': datetime.datetime(2022, 4, 14, 15, 4, 6, 63000, tzinfo=tzlocal()),\n",
       "   'ActionsEnabled': False,\n",
       "   'OKActions': [],\n",
       "   'AlarmActions': [],\n",
       "   'InsufficientDataActions': [],\n",
       "   'StateValue': 'OK',\n",
       "   'StateReason': 'Threshold Crossed: no datapoints were received for 1 period and 1 missing datapoint was treated as [NonBreaching].',\n",
       "   'StateReasonData': '{\"version\":\"1.0\",\"queryDate\":\"2022-04-14T15:04:54.683+0000\",\"statistic\":\"Average\",\"period\":60,\"recentDatapoints\":[],\"threshold\":10000.0,\"evaluatedDatapoints\":[{\"timestamp\":\"2022-04-14T15:04:00.000+0000\"}]}',\n",
       "   'StateUpdatedTimestamp': datetime.datetime(2022, 4, 14, 15, 4, 54, 687000, tzinfo=tzlocal()),\n",
       "   'MetricName': 'ModelLatency',\n",
       "   'Namespace': 'AWS/SageMaker',\n",
       "   'Statistic': 'Average',\n",
       "   'Dimensions': [{'Name': 'EndpointName', 'Value': 'smgithub2-staging'},\n",
       "    {'Name': 'VariantName', 'Value': 'AllTraffic'}],\n",
       "   'Period': 60,\n",
       "   'EvaluationPeriods': 1,\n",
       "   'Threshold': 10000.0,\n",
       "   'ComparisonOperator': 'GreaterThanOrEqualToThreshold',\n",
       "   'TreatMissingData': 'notBreaching'}],\n",
       " 'ResponseMetadata': {'RequestId': '792101d5-1c23-4e8b-9ded-17be97aeedf6',\n",
       "  'HTTPStatusCode': 200,\n",
       "  'HTTPHeaders': {'x-amzn-requestid': '792101d5-1c23-4e8b-9ded-17be97aeedf6',\n",
       "   'content-type': 'text/xml',\n",
       "   'content-length': '4226',\n",
       "   'date': 'Fri, 15 Apr 2022 02:02:52 GMT'},\n",
       "  'RetryAttempts': 0}}"
      ]
     },
     "execution_count": 326,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "### NOW Create the ALARMs\n",
    "error_alarm = f\"TestSMGitHub2Alarm-5XXErrors-{endpoint_name}\"\n",
    "latency_alarm = f\"TestSMGitHub2Alarm-ModelLatency-{endpoint_name}\"\n",
    "\n",
    "# alarm on 1% 5xx error rate for 1 minute\n",
    "create_auto_rollback_alarm(\n",
    "    error_alarm, endpoint_name, \"AllTraffic\", \"Invocation5XXErrors\", \"Average\", 1\n",
    ")\n",
    "# alarm on model latency >= 10 ms for 1 minute\n",
    "create_auto_rollback_alarm(\n",
    "    latency_alarm, endpoint_name, \"AllTraffic\", \"ModelLatency\", \"Average\", 10000\n",
    ")\n",
    "cw.describe_alarms(AlarmNames=[error_alarm, latency_alarm])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 546,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'CompositeAlarms': [],\n",
       " 'MetricAlarms': [{'AlarmName': 'TestSMGitHub2Alarm-5XXErrors-smgithub2-staging',\n",
       "   'AlarmArn': 'arn:aws:cloudwatch:us-east-1:034150676293:alarm:TestSMGitHub2Alarm-5XXErrors-smgithub2-staging',\n",
       "   'AlarmDescription': 'Test SageMaker endpoint deployment auto-rollback alarm',\n",
       "   'AlarmConfigurationUpdatedTimestamp': datetime.datetime(2022, 4, 14, 15, 4, 5, 963000, tzinfo=tzlocal()),\n",
       "   'ActionsEnabled': False,\n",
       "   'OKActions': [],\n",
       "   'AlarmActions': [],\n",
       "   'InsufficientDataActions': [],\n",
       "   'StateValue': 'OK',\n",
       "   'StateReason': 'Threshold Crossed: no datapoints were received for 1 period and 1 missing datapoint was treated as [NonBreaching].',\n",
       "   'StateReasonData': '{\"version\":\"1.0\",\"queryDate\":\"2022-04-14T15:04:27.064+0000\",\"statistic\":\"Average\",\"period\":60,\"recentDatapoints\":[],\"threshold\":1.0,\"evaluatedDatapoints\":[{\"timestamp\":\"2022-04-14T15:04:00.000+0000\"}]}',\n",
       "   'StateUpdatedTimestamp': datetime.datetime(2022, 4, 14, 15, 4, 27, 168000, tzinfo=tzlocal()),\n",
       "   'MetricName': 'Invocation5XXErrors',\n",
       "   'Namespace': 'AWS/SageMaker',\n",
       "   'Statistic': 'Average',\n",
       "   'Dimensions': [{'Name': 'EndpointName', 'Value': 'smgithub2-staging'},\n",
       "    {'Name': 'VariantName', 'Value': 'AllTraffic'}],\n",
       "   'Period': 60,\n",
       "   'EvaluationPeriods': 1,\n",
       "   'Threshold': 1.0,\n",
       "   'ComparisonOperator': 'GreaterThanOrEqualToThreshold',\n",
       "   'TreatMissingData': 'notBreaching'},\n",
       "  {'AlarmName': 'TestSMGitHub2Alarm-ModelLatency-smgithub2-staging',\n",
       "   'AlarmArn': 'arn:aws:cloudwatch:us-east-1:034150676293:alarm:TestSMGitHub2Alarm-ModelLatency-smgithub2-staging',\n",
       "   'AlarmDescription': 'Test SageMaker endpoint deployment auto-rollback alarm',\n",
       "   'AlarmConfigurationUpdatedTimestamp': datetime.datetime(2022, 4, 14, 15, 4, 6, 63000, tzinfo=tzlocal()),\n",
       "   'ActionsEnabled': False,\n",
       "   'OKActions': [],\n",
       "   'AlarmActions': [],\n",
       "   'InsufficientDataActions': [],\n",
       "   'StateValue': 'OK',\n",
       "   'StateReason': 'Threshold Crossed: 1 datapoint [5831.733333333334 (18/04/22 02:10:00)] was not greater than or equal to the threshold (10000.0).',\n",
       "   'StateReasonData': '{\"version\":\"1.0\",\"queryDate\":\"2022-04-18T02:11:54.679+0000\",\"startDate\":\"2022-04-18T02:10:00.000+0000\",\"statistic\":\"Average\",\"period\":60,\"recentDatapoints\":[5831.733333333334],\"threshold\":10000.0,\"evaluatedDatapoints\":[{\"timestamp\":\"2022-04-18T02:10:00.000+0000\",\"sampleCount\":60.0,\"value\":5831.733333333334}]}',\n",
       "   'StateUpdatedTimestamp': datetime.datetime(2022, 4, 18, 2, 11, 54, 689000, tzinfo=tzlocal()),\n",
       "   'MetricName': 'ModelLatency',\n",
       "   'Namespace': 'AWS/SageMaker',\n",
       "   'Statistic': 'Average',\n",
       "   'Dimensions': [{'Name': 'EndpointName', 'Value': 'smgithub2-staging'},\n",
       "    {'Name': 'VariantName', 'Value': 'AllTraffic'}],\n",
       "   'Period': 60,\n",
       "   'EvaluationPeriods': 1,\n",
       "   'Threshold': 10000.0,\n",
       "   'ComparisonOperator': 'GreaterThanOrEqualToThreshold',\n",
       "   'TreatMissingData': 'notBreaching'}],\n",
       " 'ResponseMetadata': {'RequestId': 'ec82ccdc-fea3-40f9-a22a-47f6fe5c9739',\n",
       "  'HTTPStatusCode': 200,\n",
       "  'HTTPHeaders': {'x-amzn-requestid': 'ec82ccdc-fea3-40f9-a22a-47f6fe5c9739',\n",
       "   'content-type': 'text/xml',\n",
       "   'content-length': '4385',\n",
       "   'date': 'Mon, 18 Apr 2022 02:40:00 GMT'},\n",
       "  'RetryAttempts': 0}}"
      ]
     },
     "execution_count": 546,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cw.describe_alarms(AlarmNames=[error_alarm, latency_alarm])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Create the BLUE Green deployment -- LINEAR --"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 545,
   "metadata": {},
   "outputs": [
    {
     "ename": "ClientError",
     "evalue": "An error occurred (ValidationException) when calling the UpdateEndpoint operation: Cannot update existing endpoint using DeploymentConfig due to unsupported features. Please create new endpoint with DeploymentConfig and retry the update request, and refer documentation for a list of exclusions.",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mClientError\u001b[0m                               Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-545-4e64564a187e>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m     19\u001b[0m                 { # -- 1st is Metrics and second is Latency \n\u001b[1;32m     20\u001b[0m                     \u001b[0;34m\"AlarmName\"\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0;34m\"TestSMGitHub2Alarm-5XXErrors-smgithub2-staging\"\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 21\u001b[0;31m                     \u001b[0;34m\"AlarmName\"\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0;34m\"TestSMGitHub2Alarm-ModelLatency-smgithub2-staging\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     22\u001b[0m                 }\n\u001b[1;32m     23\u001b[0m             ]\n",
      "\u001b[0;32m/opt/conda/lib/python3.7/site-packages/botocore/client.py\u001b[0m in \u001b[0;36m_api_call\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m    389\u001b[0m                     \"%s() only accepts keyword arguments.\" % py_operation_name)\n\u001b[1;32m    390\u001b[0m             \u001b[0;31m# The \"self\" in this scope is referring to the BaseClient.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 391\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_make_api_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0moperation_name\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    392\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    393\u001b[0m         \u001b[0m_api_call\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m__name__\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mstr\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mpy_operation_name\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/conda/lib/python3.7/site-packages/botocore/client.py\u001b[0m in \u001b[0;36m_make_api_call\u001b[0;34m(self, operation_name, api_params)\u001b[0m\n\u001b[1;32m    717\u001b[0m             \u001b[0merror_code\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mparsed_response\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"Error\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m{\u001b[0m\u001b[0;34m}\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"Code\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    718\u001b[0m             \u001b[0merror_class\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mexceptions\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfrom_code\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0merror_code\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 719\u001b[0;31m             \u001b[0;32mraise\u001b[0m \u001b[0merror_class\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mparsed_response\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0moperation_name\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    720\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    721\u001b[0m             \u001b[0;32mreturn\u001b[0m \u001b[0mparsed_response\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mClientError\u001b[0m: An error occurred (ValidationException) when calling the UpdateEndpoint operation: Cannot update existing endpoint using DeploymentConfig due to unsupported features. Please create new endpoint with DeploymentConfig and retry the update request, and refer documentation for a list of exclusions."
     ]
    }
   ],
   "source": [
    "# -- if end point has ModelMonitor and Data Capture enabled then you cannot use linear caranry \n",
    "# -- deployment gaurd rails. \n",
    "# -- have to create a new one to capture this\n",
    "sm_client.update_endpoint(\n",
    "    EndpointName=endpoint_name,\n",
    "    EndpointConfigName=ep_config_2nd_name,\n",
    "    DeploymentConfig={\n",
    "        \"BlueGreenUpdatePolicy\": {\n",
    "            \"TrafficRoutingConfiguration\": {\n",
    "                \"Type\": \"LINEAR\",\n",
    "                \"LinearStepSize\": {\n",
    "                    \"Type\": \"CAPACITY_PERCENT\",\n",
    "                    \"Value\": 20\n",
    "                },\n",
    "                \"WaitIntervalInSeconds\": 300\n",
    "            },\n",
    "            \"TerminationWaitInSeconds\": 300,\n",
    "            \"MaximumExecutionTimeoutInSeconds\": 3600\n",
    "        },\n",
    "        \"AutoRollbackConfiguration\": {\n",
    "            \"Alarms\": [\n",
    "                { # -- 1st is Metrics and second is Latency \n",
    "                    \"AlarmName\": \"TestSMGitHub2Alarm-5XXErrors-smgithub2-staging\",\n",
    "                    \"AlarmName\": \"TestSMGitHub2Alarm-ModelLatency-smgithub2-staging\"\n",
    "                }\n",
    "            ]\n",
    "        }\n",
    "    }\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(sm_client.describe_endpoint(EndpointName=endpoint_name))\n",
    "#invoke_smgithub_staging_endpoint(600, 1, False,100) # -- log every 100 steps with total of 600 invokation\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(f\"WAITING::Endpoint:name={endpoint_name}:: TO BE IN SERVICE\")\n",
    "waiter = sm_client.get_waiter('endpoint_in_service') # -- SMXGBoostCustomTweet-modelregistry-endpoint-2022-03-16-16-16-33\n",
    "waiter.wait(EndpointName=endpoint_name)\n",
    "print(f\"Endpoint:name={endpoint_name}:: is in service\")\n",
    "\n",
    "sm_client.describe_endpoint(EndpointName=endpoint_name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 103,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "b'0.00022043351782485843'"
      ]
     },
     "execution_count": 103,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "prediction"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#sm_client = sagemaker_session.boto_session.client(\"sagemaker\")\n",
    "#sm_client.delete_endpoint(EndpointName=endpoint_name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'TweetsModelPackageGroup-Example1'"
      ]
     },
     "execution_count": 39,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model_package_group_name"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Now we query the Model Package Group and Model Package"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Version of interest model=::\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "{'ModelPackageSummaryList': [{'ModelPackageGroupName': 'TweetsModelPackageGroup-Example1',\n",
       "   'ModelPackageVersion': 7,\n",
       "   'ModelPackageArn': 'arn:aws:sagemaker:us-east-1:034150676293:model-package/tweetsmodelpackagegroup-example1/7',\n",
       "   'ModelPackageDescription': 'Test-Description',\n",
       "   'CreationTime': datetime.datetime(2022, 4, 12, 21, 52, 35, 170000, tzinfo=tzlocal()),\n",
       "   'ModelPackageStatus': 'Completed',\n",
       "   'ModelApprovalStatus': 'Approved'},\n",
       "  {'ModelPackageGroupName': 'TweetsModelPackageGroup-Example1',\n",
       "   'ModelPackageVersion': 6,\n",
       "   'ModelPackageArn': 'arn:aws:sagemaker:us-east-1:034150676293:model-package/tweetsmodelpackagegroup-example1/6',\n",
       "   'ModelPackageDescription': 'Test-Description',\n",
       "   'CreationTime': datetime.datetime(2022, 4, 12, 21, 33, 27, 984000, tzinfo=tzlocal()),\n",
       "   'ModelPackageStatus': 'Completed',\n",
       "   'ModelApprovalStatus': 'Approved'}],\n",
       " 'ResponseMetadata': {'RequestId': '7723fda4-d66c-4013-be90-0ddd1cee85ad',\n",
       "  'HTTPStatusCode': 200,\n",
       "  'HTTPHeaders': {'x-amzn-requestid': '7723fda4-d66c-4013-be90-0ddd1cee85ad',\n",
       "   'content-type': 'application/x-amz-json-1.1',\n",
       "   'content-length': '704',\n",
       "   'date': 'Wed, 13 Apr 2022 15:32:17 GMT'},\n",
       "  'RetryAttempts': 0}}"
      ]
     },
     "execution_count": 75,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sm_client = sm_session.boto_session.client(\"sagemaker\") #boto3.Session().client('sagemaker')\n",
    "# -- NOW list the model versions in the group ---\n",
    "sm_client.list_model_packages(ModelPackageGroupName=model_package_group_name)\n",
    "\n",
    "# -- find the latest MODEL Package ARN\n",
    "model_of_interest_arn = \"\"\n",
    "for models_reg in sm_client.list_model_packages(\n",
    "    ModelPackageGroupName=model_package_group_name, ModelApprovalStatus=\"Approved\")['ModelPackageSummaryList']:\n",
    "    if models_reg['ModelPackageVersion'] == 9: # -- or sinmply get the latest [0] was 3 earlier \n",
    "        model_of_interest_arn= models_reg['ModelPackageArn']\n",
    "        model_name_of_interest = models_reg['ModelPackageArn']\n",
    "        \n",
    "print(f\"Version of interest model={model_of_interest_arn}::\")\n",
    "\n",
    "sm_client.list_model_packages(ModelPackageGroupName=model_package_group_name, ModelApprovalStatus=\"Approved\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'ModelPackageGroupName': 'TweetsModelPackageGroup-Example1',\n",
       " 'ModelPackageVersion': 6,\n",
       " 'ModelPackageArn': 'arn:aws:sagemaker:us-east-1:034150676293:model-package/tweetsmodelpackagegroup-example1/6',\n",
       " 'ModelPackageDescription': 'Test-Description',\n",
       " 'CreationTime': datetime.datetime(2022, 4, 12, 21, 33, 27, 984000, tzinfo=tzlocal()),\n",
       " 'InferenceSpecification': {'Containers': [{'Image': '683313688378.dkr.ecr.us-east-1.amazonaws.com/sagemaker-xgboost:1.3-1',\n",
       "    'ImageDigest': 'sha256:3a8057603ec63256677e45e545f17986102d8d4ea8516b278343d7bd72c08257',\n",
       "    'ModelDataUrl': 's3://sagemaker-grewaltempl/pipeline/model/xgbtrain/modeltweet/pipelines-whvwleu714j3-TrainTweetsStep-THACBHaQVT/output/model.tar.gz'}],\n",
       "  'SupportedTransformInstanceTypes': ['ml.m5.large'],\n",
       "  'SupportedRealtimeInferenceInstanceTypes': ['ml.t2.medium', 'ml.m5.large'],\n",
       "  'SupportedContentTypes': ['text/csv'],\n",
       "  'SupportedResponseMIMETypes': ['text/csv']},\n",
       " 'ModelPackageStatus': 'Completed',\n",
       " 'ModelPackageStatusDetails': {'ValidationStatuses': [],\n",
       "  'ImageScanStatuses': []},\n",
       " 'CertifyForMarketplace': False,\n",
       " 'ModelApprovalStatus': 'Approved',\n",
       " 'MetadataProperties': {'GeneratedBy': 'arn:aws:sagemaker:us-east-1:034150676293:pipeline/sagemakertweetspipeline/execution/g8paoczr0162'},\n",
       " 'ModelMetrics': {'ModelQuality': {'Statistics': {'ContentType': 'application/json',\n",
       "    'S3Uri': 's3://sagemaker-grewaltempl/artifact-tweets-eval/tweets-pipeline-2022-04-12-21-06-29-478/output/evaluation/evaluation.json'}},\n",
       "  'Bias': {},\n",
       "  'Explainability': {}},\n",
       " 'LastModifiedTime': datetime.datetime(2022, 4, 12, 22, 11, 41, 412000, tzinfo=tzlocal()),\n",
       " 'LastModifiedBy': {'UserProfileArn': 'arn:aws:sagemaker:us-east-1:034150676293:user-profile/d-3pm3exybgi3a/default-grewaltempl',\n",
       "  'UserProfileName': 'default-grewaltempl',\n",
       "  'DomainId': 'd-3pm3exybgi3a'},\n",
       " 'ApprovalDescription': 'testing version 6 approvals',\n",
       " 'ResponseMetadata': {'RequestId': '97db22d4-cc9f-493c-b8e6-6f3d9107fe06',\n",
       "  'HTTPStatusCode': 200,\n",
       "  'HTTPHeaders': {'x-amzn-requestid': '97db22d4-cc9f-493c-b8e6-6f3d9107fe06',\n",
       "   'content-type': 'application/x-amz-json-1.1',\n",
       "   'content-length': '1669',\n",
       "   'date': 'Wed, 13 Apr 2022 15:33:11 GMT'},\n",
       "  'RetryAttempts': 0}}"
      ]
     },
     "execution_count": 78,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sm_client.describe_model_package(ModelPackageName='arn:aws:sagemaker:us-east-1:034150676293:model-package/tweetsmodelpackagegroup-example1/6')  \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "instance_type": "ml.m5.2xlarge",
  "kernelspec": {
   "display_name": "Python 3 (Data Science)",
   "language": "python",
   "name": "python3__SAGEMAKER_INTERNAL__arn:aws:sagemaker:us-east-1:081325390199:image/datascience-1.0"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
